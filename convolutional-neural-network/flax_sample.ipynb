{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c2251ca-de16-424d-99cf-7349bf2408c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_335936/1943015193.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Any\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## To run JAX on TPU in Google Colab, uncomment the two lines below\n",
    "# import jax.tools.colab_tpu\n",
    "# jax.tools.colab_tpu.setup_tpu()\n",
    "\n",
    "## JAX\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "## Flax (NN in JAX)\n",
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError: # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "## Optax (Optimizers in JAX)\n",
    "try:\n",
    "    import optax\n",
    "except ModuleNotFoundError: # Install optax if missing\n",
    "    !pip install --quiet optax\n",
    "    import optax\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import os  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea888a12-5c2c-4bc9-b529-2a4a0ec29c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: TFRT_CPU_0\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"./data\"\n",
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./models\"\n",
    "\n",
    "# Seeding for random operations\n",
    "main_rng = random.PRNGKey(42)\n",
    "\n",
    "print(\"Device:\", jax.devices()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62e44ea2-b969-46cc-8964-24cb564f80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mean [0.49139968, 0.48215841, 0.44653091]\n",
      "Data std [0.24703223, 0.24348513, 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "DATA_MEANS = [0.49139968, 0.48215841, 0.44653091]\n",
    "DATA_STD = [0.24703223, 0.24348513, 0.26158784]\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a05317ca-7c23-4a08-8844-ba39be21111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations applied on each image => bring them into a numpy array\n",
    "def image_to_numpy(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = (img / 255. - DATA_MEANS) / DATA_STD\n",
    "    return img\n",
    "\n",
    "# We need to stack the batch elements\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "\n",
    "test_transform = image_to_numpy\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      # torchvision.transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      image_to_numpy\n",
    "                                     ])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "# We need to do a little trick because the validation set should not use the augmentation.\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for training and validation\n",
    "train_loader = data.DataLoader(train_set,\n",
    "                               batch_size=128,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=8,\n",
    "                               persistent_workers=True)\n",
    "val_loader   = data.DataLoader(val_set,\n",
    "                               batch_size=128,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=4,\n",
    "                               persistent_workers=True)\n",
    "test_loader  = data.DataLoader(test_set,\n",
    "                               batch_size=128,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=4,\n",
    "                               persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5f3ef50-6857-4246-a2ba-76633ba2dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mean [-0.06992233 -0.02000982  0.04763538]\n",
      "Batch std [1.00894108 0.98669324 0.99825148]\n"
     ]
    }
   ],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Batch mean\", imgs.mean(axis=(0,1,2)))\n",
    "print(\"Batch std\", imgs.std(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a37c588-7508-4340-aede-bd99f5a7d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    # A simple extension of TrainState to also include batch statistics\n",
    "    batch_stats: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adc322da-c4c6-447e-94e0-051b23b86987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerModule:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_name : str,\n",
    "                 model_class : nn.Module,\n",
    "                 model_hparams : dict,\n",
    "                 optimizer_name : str,\n",
    "                 optimizer_hparams : dict,\n",
    "                 exmp_imgs : Any,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Module for summarizing all training functionalities for classification on CIFAR10.\n",
    "\n",
    "        Inputs:\n",
    "            model_name - String of the class name, used for logging and saving\n",
    "            model_class - Class implementing the neural network\n",
    "            model_hparams - Hyperparameters of the model, used as input to model constructor\n",
    "            optimizer_name - String of the optimizer name, supporting ['sgd', 'adam', 'adamw']\n",
    "            optimizer_hparams - Hyperparameters of the optimizer, including learning rate as 'lr'\n",
    "            exmp_imgs - Example imgs, used as input to initialize the model\n",
    "            seed - Seed to use in the model initialization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model_class = model_class\n",
    "        self.model_hparams = model_hparams\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.optimizer_hparams = optimizer_hparams\n",
    "        self.seed = seed\n",
    "        # Create empty model. Note: no parameters yet\n",
    "        self.model = self.model_class(**self.model_hparams)\n",
    "        # Prepare logging\n",
    "        self.log_dir = os.path.join(CHECKPOINT_PATH, self.model_name)\n",
    "        self.logger = SummaryWriter(log_dir=self.log_dir)\n",
    "        # Create jitted training and eval functions\n",
    "        self.create_functions()\n",
    "        # Initialize model\n",
    "        self.init_model(exmp_imgs)\n",
    "\n",
    "    def create_functions(self):\n",
    "        # Function to calculate the classification loss and accuracy for a model\n",
    "        def calculate_loss(params, batch_stats, batch, train):\n",
    "            imgs, labels = batch\n",
    "            # Run model. During training, we need to update the BatchNorm statistics.\n",
    "            outs = self.model.apply({'params': params, 'batch_stats': batch_stats},\n",
    "                                    imgs,\n",
    "                                    train=train,\n",
    "                                    mutable=['batch_stats'] if train else False)\n",
    "            logits, new_model_state = outs if train else (outs, None)\n",
    "            loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "            acc = (logits.argmax(axis=-1) == labels).mean()\n",
    "            return loss, (acc, new_model_state)\n",
    "        # Training function\n",
    "        def train_step(state, batch):\n",
    "            loss_fn = lambda params: calculate_loss(params, state.batch_stats, batch, train=True)\n",
    "            # Get loss, gradients for loss, and other outputs of loss function\n",
    "            ret, grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "            loss, acc, new_model_state = ret[0], *ret[1]\n",
    "            # Update parameters and batch statistics\n",
    "            state = state.apply_gradients(grads=grads, batch_stats=new_model_state['batch_stats'])\n",
    "            return state, loss, acc\n",
    "        # Eval function\n",
    "        def eval_step(state, batch):\n",
    "            # Return the accuracy for a single batch\n",
    "            _, (acc, _) = calculate_loss(state.params, state.batch_stats, batch, train=False)\n",
    "            return acc\n",
    "        # jit for efficiency\n",
    "        self.train_step = jax.jit(train_step)\n",
    "        self.eval_step = jax.jit(eval_step)\n",
    "\n",
    "    def init_model(self, exmp_imgs):\n",
    "        # Initialize model\n",
    "        init_rng = jax.random.PRNGKey(self.seed)\n",
    "        variables = self.model.init(init_rng, exmp_imgs)\n",
    "        self.init_params, self.init_batch_stats = variables['params'], variables['batch_stats']\n",
    "        self.state = None\n",
    "\n",
    "    def init_optimizer(self, num_epochs, num_steps_per_epoch):\n",
    "        # Initialize learning rate schedule and optimizer\n",
    "        if self.optimizer_name.lower() == 'adam':\n",
    "            opt_class = optax.adam\n",
    "        elif self.optimizer_name.lower() == 'adamw':\n",
    "            opt_class = optax.adamw\n",
    "        elif self.optimizer_name.lower() == 'sgd':\n",
    "            opt_class = optax.sgd\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer \"{opt_class}\"'\n",
    "        # We decrease the learning rate by a factor of 0.1 after 60% and 85% of the training\n",
    "        lr_schedule = optax.piecewise_constant_schedule(\n",
    "            init_value=self.optimizer_hparams.pop('lr'),\n",
    "            boundaries_and_scales=\n",
    "                {int(num_steps_per_epoch*num_epochs*0.6): 0.1,\n",
    "                 int(num_steps_per_epoch*num_epochs*0.85): 0.1}\n",
    "        )\n",
    "        # Clip gradients at max value, and evt. apply weight decay\n",
    "        transf = [optax.clip(1.0)]\n",
    "        if opt_class == optax.sgd and 'weight_decay' in self.optimizer_hparams:  # wd is integrated in adamw\n",
    "            transf.append(optax.add_decayed_weights(self.optimizer_hparams.pop('weight_decay')))\n",
    "        optimizer = optax.chain(\n",
    "            *transf,\n",
    "            opt_class(lr_schedule, **self.optimizer_hparams)\n",
    "        )\n",
    "        # Initialize training state\n",
    "        self.state = TrainState.create(apply_fn=self.model.apply,\n",
    "                                       params=self.init_params if self.state is None else self.state.params,\n",
    "                                       batch_stats=self.init_batch_stats if self.state is None else self.state.batch_stats,\n",
    "                                       tx=optimizer)\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, num_epochs=200):\n",
    "        # Train model for defined number of epochs\n",
    "        # We first need to create optimizer and the scheduler for the given number of epochs\n",
    "        self.init_optimizer(num_epochs, len(train_loader))\n",
    "        # Track best eval accuracy\n",
    "        best_eval = 0.0\n",
    "        for epoch_idx in tqdm(range(1, num_epochs+1)):\n",
    "            self.train_epoch(train_loader, epoch=epoch_idx)\n",
    "            if epoch_idx % 2 == 0:\n",
    "                eval_acc = self.eval_model(val_loader)\n",
    "                self.logger.add_scalar('val/acc', eval_acc, global_step=epoch_idx)\n",
    "                if eval_acc >= best_eval:\n",
    "                    best_eval = eval_acc\n",
    "                    self.save_model(step=epoch_idx)\n",
    "                self.logger.flush()\n",
    "\n",
    "    def train_epoch(self, train_loader, epoch):\n",
    "        # Train model for one epoch, and log avg loss and accuracy\n",
    "        metrics = defaultdict(list)\n",
    "        for batch in tqdm(train_loader, desc='Training', leave=False):\n",
    "            self.state, loss, acc = self.train_step(self.state, batch)\n",
    "            metrics['loss'].append(loss)\n",
    "            metrics['acc'].append(acc)\n",
    "        for key in metrics:\n",
    "            avg_val = np.stack(jax.device_get(metrics[key])).mean()\n",
    "            self.logger.add_scalar('train/'+key, avg_val, global_step=epoch)\n",
    "\n",
    "    def eval_model(self, data_loader):\n",
    "        # Test model on all images of a data loader and return avg loss\n",
    "        correct_class, count = 0, 0\n",
    "        for batch in data_loader:\n",
    "            acc = self.eval_step(self.state, batch)\n",
    "            correct_class += acc * batch[0].shape[0]\n",
    "            count += batch[0].shape[0]\n",
    "        eval_acc = (correct_class / count).item()\n",
    "        return eval_acc\n",
    "\n",
    "    def save_model(self, step=0):\n",
    "        # Save current model at certain training iteration\n",
    "        checkpoints.save_checkpoint(ckpt_dir=self.log_dir,\n",
    "                                    target={'params': self.state.params,\n",
    "                                            'batch_stats': self.state.batch_stats},\n",
    "                                    step=step,\n",
    "                                   overwrite=True)\n",
    "\n",
    "    def load_model(self, pretrained=False):\n",
    "        # Load model. We use different checkpoint for pretrained models\n",
    "        if not pretrained:\n",
    "            state_dict = checkpoints.restore_checkpoint(ckpt_dir=self.log_dir, target=None)\n",
    "        else:\n",
    "            state_dict = checkpoints.restore_checkpoint(ckpt_dir=os.path.join(CHECKPOINT_PATH, f'{self.model_name}.ckpt'), target=None)\n",
    "        self.state = TrainState.create(apply_fn=self.model.apply,\n",
    "                                       params=state_dict['params'],\n",
    "                                       batch_stats=state_dict['batch_stats'],\n",
    "                                       tx=self.state.tx if self.state else optax.sgd(0.1)   # Default optimizer\n",
    "                                      )\n",
    "\n",
    "    def checkpoint_exists(self):\n",
    "        # Check whether a pretrained model exist for this autoencoder\n",
    "        return os.path.isfile(os.path.join(CHECKPOINT_PATH, f'{self.model_name}.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6ab9321-7032-4658-ab39-b6b11a4c5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(*args, num_epochs=5, **kwargs):\n",
    "    # Create a trainer module with specified hyperparameters\n",
    "    trainer = TrainerModule(*args, **kwargs)\n",
    "    if not trainer.checkpoint_exists():  # Skip training if pretrained model exists\n",
    "        trainer.train_model(train_loader, val_loader, num_epochs=num_epochs)\n",
    "        trainer.load_model()\n",
    "    else:\n",
    "        trainer.load_model(pretrained=True)\n",
    "    # Test trained model\n",
    "    val_acc = trainer.eval_model(val_loader)\n",
    "    test_acc = trainer.eval_model(test_loader)\n",
    "    return trainer, {'val': val_acc, 'test': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89d7bfed-cb54-4ef8-8d56-2841a24381d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetV2(nn.Module):\n",
    "    num_classes : int\n",
    "    act_fn : callable\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=True):\n",
    "        \n",
    "        x = nn.BatchNorm()(x, use_running_average=not train)\n",
    "        \n",
    "        # Input layer\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 3) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 1\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=16, kernel_size=(3, 3), padding=1)(x)  # (4, 32, 32, 16) -> (4, 32, 32, 16)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 4\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1, strides=2)(x)  # (4, 32, 32, 16) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1)(x)  # (4, 16, 16, 32) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 5\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1)(x)  # (4, 16, 16, 32) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1)(x)  # (4, 16, 16, 32) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 6\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1)(x)  # (4, 16, 16, 32) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), padding=1)(x)  # (4, 16, 16, 32) -> (4, 16, 16, 32)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 7\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1, strides=2)(x)  # (4, 16, 16, 32) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1)(x)  # (4, 8, 8, 64) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 8\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1)(x)  # (4, 8, 8, 64) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1)(x)  # (4, 8, 8, 64) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Block 9\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1)(x)  # (4, 8, 8, 64) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), padding=1)(x)  # (4, 8, 8, 64) -> (4, 8, 8, 64)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        # Pooling \n",
    "        x = nn.avg_pool(x, window_shape=(8, 8)) # (4, 8, 8, 64) -> (4, 1, 1, 64)\n",
    "        x = x.flatten()  # flatten (4, 1, 1, 64) -> (4, 64)\n",
    "        \n",
    "        # Output \n",
    "        x = nn.Dense(features=10)(x)\n",
    "        x = nn.log_softmax(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "312e016e-ec91-435c-a585-649c2adc19a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\n",
      "Training:   0%|                                         | 0/351 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "indices and arr must have the same number of dimensions; 2 vs. 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer, results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResNetV2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResNetV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_hparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mact_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madamw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moptimizer_hparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mexmp_imgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_put\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [48], line 5\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[0;34m(num_epochs, *args, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainerModule(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mcheckpoint_exists():  \u001b[38;5;66;03m# Skip training if pretrained model exists\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn [51], line 116\u001b[0m, in \u001b[0;36mTrainerModule.train_model\u001b[0;34m(self, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m    114\u001b[0m best_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    118\u001b[0m         eval_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_model(val_loader)\n",
      "Cell \u001b[0;32mIn [51], line 129\u001b[0m, in \u001b[0;36mTrainerModule.train_epoch\u001b[0;34m(self, train_loader, epoch)\u001b[0m\n\u001b[1;32m    127\u001b[0m metrics \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    131\u001b[0m     metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [51], line 57\u001b[0m, in \u001b[0;36mTrainerModule.create_functions.<locals>.train_step\u001b[0;34m(state, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m params: calculate_loss(params, state\u001b[38;5;241m.\u001b[39mbatch_stats, batch, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Get loss, gradients for loss, and other outputs of loss function\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m ret, grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m loss, acc, new_model_state \u001b[38;5;241m=\u001b[39m ret[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mret[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Update parameters and batch statistics\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [51], line 55\u001b[0m, in \u001b[0;36mTrainerModule.create_functions.<locals>.train_step.<locals>.<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[0;32m---> 55\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m params: \u001b[43mcalculate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Get loss, gradients for loss, and other outputs of loss function\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     ret, grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(state\u001b[38;5;241m.\u001b[39mparams)\n",
      "Cell \u001b[0;32mIn [51], line 50\u001b[0m, in \u001b[0;36mTrainerModule.create_functions.<locals>.calculate_loss\u001b[0;34m(params, batch_stats, batch, train)\u001b[0m\n\u001b[1;32m     45\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mapply({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_stats},\n\u001b[1;32m     46\u001b[0m                         imgs,\n\u001b[1;32m     47\u001b[0m                         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m     48\u001b[0m                         mutable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m logits, new_model_state \u001b[38;5;241m=\u001b[39m outs \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m (outs, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax_cross_entropy_with_integer_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     51\u001b[0m acc \u001b[38;5;241m=\u001b[39m (logits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, (acc, new_model_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax-flax-cpu/lib/python3.8/site-packages/optax/_src/loss.py:203\u001b[0m, in \u001b[0;36msoftmax_cross_entropy_with_integer_labels\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m    201\u001b[0m logits_max \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m logits \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mstop_gradient(logits_max)\n\u001b[0;32m--> 203\u001b[0m label_logits \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    204\u001b[0m log_normalizers \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlog(jnp\u001b[38;5;241m.\u001b[39msum(jnp\u001b[38;5;241m.\u001b[39mexp(logits), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_normalizers \u001b[38;5;241m-\u001b[39m label_logits\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax-flax-cpu/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3699\u001b[0m, in \u001b[0;36mtake_along_axis\u001b[0;34m(arr, indices, axis, mode)\u001b[0m\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m!=\u001b[39m ndim(indices):\n\u001b[1;32m   3698\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices and arr must have the same number of dimensions; \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m vs. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3699\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(ndim(indices), ndim(arr)))\n\u001b[1;32m   3700\u001b[0m axis \u001b[38;5;241m=\u001b[39m _canonicalize_axis(axis, rank)\n\u001b[1;32m   3702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace\u001b[39m(tup, val):\n",
      "\u001b[0;31mValueError\u001b[0m: indices and arr must have the same number of dimensions; 2 vs. 1"
     ]
    }
   ],
   "source": [
    "trainer, results = train_classifier(model_class=ResNetV2,\n",
    "                                    model_name=\"ResNetV2\",\n",
    "                                    model_hparams={\"num_classes\": 10,\n",
    "                                                   \"act_fn\": nn.relu},\n",
    "                                    optimizer_name=\"adamw\",\n",
    "                                    optimizer_hparams={\"lr\": 1e-3,\n",
    "                                                       \"weight_decay\": 1e-4},\n",
    "                                    exmp_imgs=jax.device_put(\n",
    "                                        next(iter(train_loader))[0]),\n",
    "                                    num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32699e20-6b1f-4805-8c5e-b07cf14798a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-flax-cpu",
   "language": "python",
   "name": "jax-flax-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
