{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c3abc8-d0e2-422e-b491-6a78890a2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Optimise #deep learning framework\n",
    "using MLDatasets # to load dataset \n",
    "using Functors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c708d2-0094-402a-84f6-5e8ad1dd4358",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(features = [0.29411766 0.27058825 … 0.8117647 0.88235295; 0.26666668 0.23921569 … 0.8392157 0.8784314; … ; 0.4117647 0.36862746 … 0.8509804 0.8745098; 0.54901963 0.4627451 … 0.8901961 0.90588236;;; 0.19607843 0.19215687 … 0.6745098 0.7411765; 0.1764706 0.15686275 … 0.7058824 0.7411765; … ; 0.33333334 0.29411766 … 0.7607843 0.78039217; 0.4627451 0.3764706 … 0.8 0.8117647;;; 0.12156863 0.1254902 … 0.5529412 0.6156863; 0.12941177 0.11372549 … 0.5803922 0.6156863; … ; 0.28627452 0.23529412 … 0.61960787 0.627451; 0.45882353 0.3647059 … 0.65882355 0.65882355;;;; 0.7647059 0.8627451 … 0.29803923 0.2509804; 0.7411765 0.7411765 … 0.2627451 0.2; … ; 0.6901961 0.827451 … 0.4392157 0.4509804; 0.6392157 0.70980394 … 0.42352942 0.43137255;;; 0.7490196 0.85882354 … 0.27450982 0.23137255; 0.7294118 0.73333335 … 0.23529412 0.17254902; … ; 0.69411767 0.83137256 … 0.47843137 0.47058824; 0.6431373 0.7176471 … 0.4509804 0.45882353;;; 0.73333335 0.85490197 … 0.2627451 0.22745098; 0.70980394 0.7176471 … 0.20392157 0.14509805; … ; 0.69803923 0.8235294 … 0.33333334 0.34901962; 0.64705884 0.6784314 … 0.32941177 0.34509805;;;; 0.37254903 0.4117647 … 0.70980394 0.77254903; 0.35686275 0.39215687 … 0.7254902 0.77254903; … ; 0.40392157 0.41960785 … 0.6156863 0.5686275; 0.49019608 0.43529412 … 0.5686275 0.6039216;;; 0.4509804 0.4862745 … 0.61960787 0.65882355; 0.4392157 0.46666667 … 0.6313726 0.654902; … ; 0.49411765 0.49019608 … 0.5019608 0.48235294; 0.5647059 0.49019608 … 0.45882353 0.52156866;;; 0.2901961 0.28235295 … 0.41568628 0.49019608; 0.2901961 0.2784314 … 0.43529412 0.48235294; … ; 0.33333334 0.3372549 … 0.36078432 0.34901962; 0.39607844 0.32941177 … 0.32156864 0.3882353;;;; … ;;;; 0.13725491 0.22352941 … 0.23921569 0.17254902; 0.15686275 0.17254902 … 0.21568628 0.18039216; … ; 0.30980393 0.5529412 … 0.06666667 0.08235294; 0.34901962 0.45490196 … 0.02745098 0.047058824;;; 0.69803923 0.7137255 … 0.26666668 0.21960784; 0.6901961 0.72156864 … 0.27450982 0.25882354; … ; 0.5764706 0.69411767 … 0.13725491 0.16862746; 0.5803922 0.58431375 … 0.09019608 0.12156863;;; 0.92156863 0.91764706 … 0.29411766 0.28627452; 0.9372549 0.98039216 … 0.3372549 0.34509805; … ; 0.77254903 0.80784315 … 0.20784314 0.25882354; 0.7411765 0.6862745 … 0.1254902 0.19607843;;;; 0.7411765 0.7607843 … 0.7764706 0.7764706; 0.7294118 0.7490196 … 0.7411765 0.7411765; … ; 0.6745098 0.67058825 … 0.6862745 0.76862746; 0.6627451 0.654902 … 0.6862745 0.7647059;;; 0.827451 0.8235294 … 0.74509805 0.7411765; 0.8156863 0.8117647 … 0.70980394 0.70980394; … ; 0.7607843 0.7490196 … 0.6627451 0.7411765; 0.7607843 0.74509805 … 0.6627451 0.74509805;;; 0.9411765 0.9372549 … 0.6666667 0.6784314; 0.9254902 0.9254902 … 0.62352943 0.63529414; … ; 0.87058824 0.85490197 … 0.6117647 0.67058825; 0.8627451 0.84705883 … 0.6039216 0.67058825;;;; 0.8980392 0.87058824 … 0.5372549 0.47843137; 0.9254902 0.9372549 … 0.50980395 0.4627451; … ; 0.8666667 0.8901961 … 0.7921569 0.6431373; 0.87058824 0.8235294 … 0.83137256 0.6392157;;; 0.8980392 0.8666667 … 0.5176471 0.46666667; 0.92941177 0.9372549 … 0.49803922 0.45490196; … ; 0.8745098 0.89411765 … 0.7882353 0.6431373; 0.8745098 0.827451 … 0.827451 0.6392157;;; 0.9372549 0.8980392 … 0.49411765 0.44705883; 0.96862745 0.9764706 … 0.47058824 0.43137255; … ; 0.91764706 0.93333334 … 0.7764706 0.63529414; 0.9137255 0.8627451 … 0.8117647 0.6313726], targets = [7, 1, 4, 1, 0, 2, 2, 5, 9, 6  …  4, 2, 0, 1, 0, 2, 6, 9, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full training set\n",
    "train_x, train_y = CIFAR10(split=:train)[1:45000]\n",
    "\n",
    "# load the rest in training for validation\n",
    "validate_x, validate_y = CIFAR10(split=:train)[45001:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d82f1-0b52-48be-9294-4818dd193165",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D Convolution in Flux\n",
    "\n",
    "\n",
    "**Flux.Conv — Type** \n",
    "\n",
    "Conv(filter, in => out, σ = identity;\n",
    "     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init])\n",
    "\n",
    "\n",
    "Standard convolutional layer. _filter_ is a tuple of integers specifying the size of the convolutional kernel; _in_ and _out_ specify the number of input and output channels.\n",
    "\n",
    "Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a 100×100×3×1 array, and a batch of 50 would be a 100×100×3×50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5,5), a 2-tuple of integers.\n",
    "\n",
    "To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N+2, where size(x, N+1) == in is the number of input channels, and size(x, ndims(x)) is (as always) the number of observations in a batch. Then:\n",
    "\n",
    "- filter should be a tuple of N integers.\n",
    "- Keywords stride and dilation should each be either single integer, or a tuple with N integers.\n",
    "- Keyword pad specifies the number of elements added to the borders of the data array. It can be\n",
    "    - a single integer for equal padding all around,\n",
    "    - a tuple of N integers, to apply the same padding at begin/end of each spatial dimension,\n",
    "    - a tuple of 2*N integers, for asymmetric padding, or\n",
    "    - the singleton _SamePad()_, to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension.\n",
    "- Keyword groups is expected to be an Int. It specifies the number of groups to divide a convolution into.\n",
    "\n",
    "Keywords to control initialization of the layer:\n",
    "\n",
    "- init - Function used to generate initial weights. Defaults to glorot_uniform.\n",
    "- bias - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to false, or another vector can be provided such as bias = randn(Float32, out).\n",
    "            \n",
    "            \n",
    "**Flux.Conv - Method**\n",
    "_Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])_\n",
    "\n",
    "Constructs a convolutional layer with the given weight and bias. Accepts the same keywords and has the same defaults as Conv(k::NTuple{N,Integer}, ch::Pair{<:Integer,<:Integer}, σ; ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2f977-ceca-49d4-99cc-1d95fd2d83b3",
   "metadata": {},
   "source": [
    "## ResNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa38753-53a6-4b50-b94f-eb18582f1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNetLayer\n",
    "    conv1::Flux.Conv\n",
    "    conv2::Flux.Conv\n",
    "    bn1::Flux.BatchNorm\n",
    "    bn2::Flux.BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride1::Int\n",
    "    stride2::Int\n",
    "    pad1::Int\n",
    "    pad2::Int\n",
    "end\n",
    "\n",
    "@functor ResNetLayer (conv1, conv2, bn1, bn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b343c374-5db9-4b31-81d4-824004defb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residual_identity (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride1\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        x_id = copy(x[begin:2:end, begin:2:end, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d97150-1683-4dd1-90b0-0296041562df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ResNetLayer(in_channels::Int, channels::Int; stride1=1, stride2=1, f=relu, pad1=0, pad2=0)\n",
    "    bn1 = Flux.BatchNorm(in_channels)\n",
    "    conv1 = Flux.Conv((3,3), in_channels=>channels, f; stride=stride1, pad=pad1)\n",
    "    bn2 = Flux.BatchNorm(channels)\n",
    "    conv2 = Flux.Conv((3,3), channels=>channels, f; stride=stride2, pad=pad2)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride1, stride2, pad1, pad2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097c8042-c375-430a-947f-0a9bf62f4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z)\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2640d473-1b75-4705-b8a4-269333e2eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ResNetLayer(3, 10; stride1=2, stride2=1, pad1=1, pad2=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf65a7c-2ab3-4d00-9ad4-bad8bec4b6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 10, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = randn(Float32, (64, 64, 3, 2));\n",
    "y = l(x);\n",
    "size(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "uw-julia-1-8-2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
