{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf850f1c-0afa-4fe7-9bae-e5afb8931698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "using MLDatasets;\n",
    "using MLUtils: DataLoader;\n",
    "using MLDataPattern;\n",
    "using ImageCore;\n",
    "using Augmentor;\n",
    "using ImageFiltering;\n",
    "using MappedArrays;\n",
    "using Random;\n",
    "using Flux: DataLoader;\n",
    "using Functors;\n",
    "using Optimisers;\n",
    "#using Zygote;\n",
    "using Statistics;\n",
    "#using Yota;\n",
    "using TimerOutputs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afd6c4f-ec3a-4bd6-9772-f0f0cf2925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa692d0-cc2b-4967-a4db-471bd1ddaa74",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb690630-c234-4317-ba4e-2a616a90c91b",
   "metadata": {},
   "source": [
    "* Inputs: batches of (32 x 32) RGB images\n",
    "    * Tensor size (32, 32, 3, N) in WHCN dimensions\n",
    "    * Values between [0, 1]\n",
    "* For all data: ImageNet normalization\n",
    "    * Subtract means [0.485, 0.456, 0.406]\n",
    "    * Divide by standard deviations [0.229, 0.224, 0.225]\n",
    "* Augment training data only:\n",
    "    * Permute to CWHN (3, 32, 32, N)\n",
    "    * Convert to RGB image for Augmentor.jl package to process (32, 32, N)\n",
    "    * 4 pixel padding on each side (40, 40, N)\n",
    "    * Random horizontal flip\n",
    "    * (32 x 32) crop from augmented image (32, 32, N)\n",
    "    * Convert to tensors (3, 32, 32, N)\n",
    "    * Permute to WHCN (32, 32, 3, N)\n",
    "* Batch and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c708d2-0094-402a-84f6-5e8ad1dd4358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset CIFAR10:\n",
       "  metadata  =>    Dict{String, Any} with 2 entries\n",
       "  split     =>    :test\n",
       "  features  =>    32×32×3×10000 Array{Float32, 4}\n",
       "  targets   =>    10000-element Vector{Int64}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = MLDatasets.CIFAR10(Tx=Float32, split=:train)\n",
    "test_data = MLDatasets.CIFAR10(Tx=Float32, split=:test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2530170-3449-444d-a64f-dba58b89b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 50000), (32, 32, 3, 10000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_data.features;\n",
    "train_y = train_data.targets;\n",
    "\n",
    "test_x = test_data.features;\n",
    "test_y = test_data.targets;\n",
    "size(train_x), size(test_x)  # Data is in shape WHCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a22570-3246-49dc-8c23-bc57c9404684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitobs (generic function with 11 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "# Copied from https://github.com/JuliaML/MLUtils.jl/blob/v0.2.11/src/splitobs.jl#L65\n",
    "# obsview doesn't work with this data, so use getobs instead\n",
    "\n",
    "import MLDataPattern.splitobs;\n",
    "\n",
    "function splitobs(data; at, shuffle::Bool=false)\n",
    "    if shuffle\n",
    "        data = shuffleobs(data)\n",
    "    end\n",
    "    n = numobs(data)\n",
    "    return map(idx -> MLDataPattern.getobs(data, idx), splitobs(n, at))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18be42de-16de-4992-ada7-cc82bf801b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 45000), (32, 32, 3, 5000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = splitobs((train_x, train_y), at=0.9, shuffle=true);\n",
    "\n",
    "train_x, train_y = train;\n",
    "val_x, val_y = val;\n",
    "\n",
    "size(train_x), size(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9c1a37-2a10-47a5-bbb0-aaef92e939ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the data\n",
    "\n",
    "means = reshape([0.485, 0.465, 0.406], (1, 1, 3, 1))\n",
    "stdevs = reshape([0.229, 0.224, 0.225], (1, 1, 3, 1))\n",
    "normalize(x) = (x .- means) ./ stdevs\n",
    "\n",
    "train_x = normalize(train_x);\n",
    "val_x = normalize(val_x);\n",
    "test_x = normalize(test_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d001f8e-25a0-42a9-b7f9-331d22bd555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook testing: Use less data\n",
    "train_x, train_y = MLDatasets.getobs((train_x, train_y), 1:500);\n",
    "\n",
    "val_x, val_y = MLDatasets.getobs((val_x, val_y), 1:50);\n",
    "\n",
    "test_x, test_y = MLDatasets.getobs((test_x, test_y), 1:50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9386cca-9d96-4108-a4b7-19944809dc82",
   "metadata": {},
   "source": [
    "# Data augmentation pipeline with Augmentor.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883784e-b7c1-4afb-8de3-12e746fe0fde",
   "metadata": {},
   "source": [
    "By default, batch is the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f2980d7-184d-48b6-9240-e9611efdb94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the training data for further augmentation\n",
    "train_x_padded = padarray(train_x, Fill(0, (4, 4, 0, 0)));  \n",
    "size(train_x_padded)  # Should be (40, 40, 3, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fc6e65-62a6-4a88-9d6c-ce338108e160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-step Augmentor.ImmutablePipeline:\n",
       " 1.) Permute dimension order to (3, 1, 2)\n",
       " 2.) Combine color channels into colorant RGB\n",
       " 3.) Either: (50%) Flip the X axis. (50%) No operation.\n",
       " 4.) Crop random window with size (32, 32)\n",
       " 5.) Split colorant into its color channels\n",
       " 6.) Permute dimension order to (2, 3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = PermuteDims((3, 1, 2)) |> CombineChannels(RGB) |> Either(FlipX(), NoOp()) |> RCropSize(32, 32) |> SplitChannels() |> PermuteDims((2, 3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888cb0f7-cba7-4ee5-8383-000905dabe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an output array for augmented images\n",
    "outbatch(X) = Array{Float32}(undef, (32, 32, 3, nobs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "648c6a23-4dad-4420-a90c-d9d03aca3758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmentbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that takes a batch (images and targets) and augments the images\n",
    "augmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b19fd6e-e330-4e5b-811f-ebf77d19ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The specified values for size and/or count will result in 4 unused data points\n",
      "└ @ MLDataPattern /home/araising/.julia/packages/MLDataPattern/2yPuO/src/dataview.jl:205\n"
     ]
    }
   ],
   "source": [
    "# Shuffled and batched dataset of augmented images\n",
    "train_batch_size = 16\n",
    "\n",
    "train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328e7811-6d67-4e16-8bb5-5c2694bf0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Validation data\n",
    "test_batch_size = 32\n",
    "\n",
    "val_loader = DataLoader((val_x, val_y), shuffle=true, batchsize=test_batch_size);\n",
    "test_loader = DataLoader((test_x, test_y), shuffle=true, batchsize=test_batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d82f1-0b52-48be-9294-4818dd193165",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D Convolution in Flux\n",
    "\n",
    "\n",
    "**Flux.Conv — Type** \n",
    "\n",
    "Conv(filter, in => out, σ = identity;\n",
    "     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init])\n",
    "\n",
    "\n",
    "Standard convolutional layer. _filter_ is a tuple of integers specifying the size of the convolutional kernel; _in_ and _out_ specify the number of input and output channels.\n",
    "\n",
    "Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a 100×100×3×1 array, and a batch of 50 would be a 100×100×3×50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5,5), a 2-tuple of integers.\n",
    "\n",
    "To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N+2, where size(x, N+1) == in is the number of input channels, and size(x, ndims(x)) is (as always) the number of observations in a batch. Then:\n",
    "\n",
    "- filter should be a tuple of N integers.\n",
    "- Keywords stride and dilation should each be either single integer, or a tuple with N integers.\n",
    "- Keyword pad specifies the number of elements added to the borders of the data array. It can be\n",
    "    - a single integer for equal padding all around,\n",
    "    - a tuple of N integers, to apply the same padding at begin/end of each spatial dimension,\n",
    "    - a tuple of 2*N integers, for asymmetric padding, or\n",
    "    - the singleton _SamePad()_, to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension.\n",
    "- Keyword groups is expected to be an Int. It specifies the number of groups to divide a convolution into.\n",
    "\n",
    "Keywords to control initialization of the layer:\n",
    "\n",
    "- init - Function used to generate initial weights. Defaults to glorot_uniform.\n",
    "- bias - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to false, or another vector can be provided such as bias = randn(Float32, out).\n",
    "            \n",
    "            \n",
    "**Flux.Conv - Method**\n",
    "_Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])_\n",
    "\n",
    "Constructs a convolutional layer with the given weight and bias. Accepts the same keywords and has the same defaults as Conv(k::NTuple{N,Integer}, ch::Pair{<:Integer,<:Integer}, σ; ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2f977-ceca-49d4-99cc-1d95fd2d83b3",
   "metadata": {},
   "source": [
    "## ResNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa38753-53a6-4b50-b94f-eb18582f1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mutable struct ResNetLayer\n",
    "    conv1::Flux.Conv\n",
    "    conv2::Flux.Conv\n",
    "    bn1::Flux.BatchNorm\n",
    "    bn2::Flux.BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride::Int\n",
    "    # stride2::Int\n",
    "    # pad1::Int\n",
    "    # pad2::Int\n",
    "end\n",
    "\n",
    "@functor ResNetLayer (conv1, conv2, bn1, bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b343c374-5db9-4b31-81d4-824004defb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residual_identity (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        inds = CartesianIndices((1:stride:w, 1:stride:h))\n",
    "        x_id = copy(x[inds, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(T, w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d97150-1683-4dd1-90b0-0296041562df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ResNetLayer(in_channels::Int, channels::Int; stride=1, f=relu)\n",
    "    bn1 = Flux.BatchNorm(in_channels)\n",
    "    conv1 = Flux.Conv((3,3), in_channels=>channels; stride=stride, pad=1, init=Flux.kaiming_uniform, bias=false)\n",
    "    bn2 = Flux.BatchNorm(channels)\n",
    "    conv2 = Flux.Conv((3,3), channels=>channels; stride=1, pad=1, init=Flux.kaiming_uniform, bias=false)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097c8042-c375-430a-947f-0a9bf62f4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z)\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b31ca-2a3b-4f99-8918-e61935fed1fe",
   "metadata": {},
   "source": [
    "# ResNet20 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7900215-2bc6-4004-bce4-64c64b2bbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNet20\n",
    "    input_conv::Flux.Conv\n",
    "    resnet_blocks::Chain\n",
    "    pool::GlobalMeanPool\n",
    "    dense::Flux.Dense\n",
    "end\n",
    "\n",
    "@functor ResNet20\n",
    "\n",
    "function ResNet20(in_channels::Int, num_classes::Int)\n",
    "    resnet_blocks = Chain(\n",
    "        block_1 = ResNetLayer(16, 16),\n",
    "        block_2 = ResNetLayer(16, 16),\n",
    "        block_3 = ResNetLayer(16, 16),\n",
    "        block_4 = ResNetLayer(16, 32; stride=2),\n",
    "        block_5 = ResNetLayer(32, 32),\n",
    "        block_6 = ResNetLayer(32, 32),\n",
    "        block_7 = ResNetLayer(32, 64; stride=2),\n",
    "        block_8 = ResNetLayer(64, 64),\n",
    "        block_9 = ResNetLayer(64, 64)\n",
    "    )\n",
    "    return ResNet20(\n",
    "        Flux.Conv((3,3), in_channels=>16, init=Flux.kaiming_uniform, pad=1, bias=false),\n",
    "        resnet_blocks,\n",
    "        GlobalMeanPool(),\n",
    "        Dense(64 => num_classes)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (self::ResNet20)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_blocks(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.dense(z)\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ab326-0dcc-45d4-a748-7ec788b59717",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f935051-05ee-493d-83a5-e5079073b065",
   "metadata": {},
   "source": [
    "## Sparse Cross Entropy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "335cf92b-3fd1-420d-94d4-573190cc8dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse_logit_cross_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    sparse_logit_cross_entropy(logits, labels)\n",
    "\n",
    "Efficient computation of cross entropy loss with model logits and integer indices as labels.\n",
    "Integer indices are from [0,  N-1], where N is the number of classes\n",
    "Similar to TensorFlow SparseCategoricalCrossEntropy\n",
    "\n",
    "# Arguments\n",
    "- `logits::AbstractArray`: 2D model logits tensor of shape (classes, batch size)\n",
    "- `labels::AbstractArray`: 1D integer label indices of shape (batch size,)\n",
    "\n",
    "# Returns\n",
    "- `loss::Float32`: Cross entropy loss\n",
    "\"\"\"\n",
    "\n",
    "function sparse_logit_cross_entropy(logits, labels)\n",
    "    log_probs = logsoftmax(logits);\n",
    "    inds = CartesianIndex.(labels .+ 1, axes(log_probs, 2));\n",
    "    # Select indices of labels for loss\n",
    "    log_probs = log_probs[inds];\n",
    "    loss = -mean(log_probs);\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0443ca-e10a-4d41-91a1-e83ce71d2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with 3 input channels and 10 classes\n",
    "model = ResNet20(3, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341650b3-519d-4bc1-a68b-1c47b2724a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup AdamW optimizer\n",
    "β = (0.9, 0.999);\n",
    "decay = 1e-4;\n",
    "state = Optimisers.setup(Optimisers.Adam(1e-3, β, decay), model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "383cdc2f-38c5-4f32-ad4c-a1d6fad123d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create objective function to optimize\n",
    "function loss_function(model::ResNet20, x::AbstractArray, y::AbstractArray)\n",
    "    ŷ = model(x)\n",
    "    loss = sparse_logit_cross_entropy(ŷ, y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f56d791-ac41-45fb-aaf4-f97b8e68f347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x, y) = first(train_batches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "422579a1-c367-4e37-9c54-2e0524f4e02e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 2 methods)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct ResNet5\n",
    "    input_conv::Flux.Conv\n",
    "    resnet_block::ResNetLayer\n",
    "    pool::GlobalMeanPool\n",
    "    dense::Flux.Dense\n",
    "end\n",
    "\n",
    "@functor ResNet5\n",
    "\n",
    "function ResNet5(in_channels::Int, num_classes::Int)\n",
    "    return ResNet5(\n",
    "        Flux.Conv((3,3), in_channels=>16, init=Flux.kaiming_uniform, pad=1, bias=false),\n",
    "        ResNetLayer(16, 16),\n",
    "        GlobalMeanPool(),\n",
    "        Dense(16 => num_classes)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (self::ResNet5)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_block(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.dense(z)\n",
    "    return y\n",
    "end\n",
    "\n",
    "\n",
    "function loss_function(model::ResNet5, x::AbstractArray, y::AbstractArray)\n",
    "    ŷ = model(x)\n",
    "    loss = sparse_logit_cross_entropy(ŷ, y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdcd41-bb0a-48be-8a83-8a2b6080eb76",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a71d6f3-00b1-43e7-9094-b85e6ffa4700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(model, test_loader)\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for (x, y) in test_loader\n",
    "        # Get model predictions\n",
    "        # Note argmax of nd-array gives CartesianIndex\n",
    "        # Need to grab the first element of each CartesianIndex to get the true index\n",
    "        logits = model(x)\n",
    "        ŷ = map(i -> i[1], argmax(logits, dims=1))\n",
    "        append!(preds, ŷ)\n",
    "\n",
    "        # Get true labels\n",
    "        append!(targets, y)\n",
    "    end\n",
    "    accuracy = sum(preds .== targets) / length(targets)\n",
    "    return accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9b604-fb10-426d-b6bf-06e76b169686",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae02a82c-b6b4-4819-b991-ce248ae1d8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
       "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
       "                   ───────────────────────   ────────────────────────\n",
       " Tot / % measured:      1.19s /   0.0%           60.0MiB /   0.0%    \n",
       "\n",
       " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
       " ────────────────────────────────────────────────────────────────────\n",
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup timing output\n",
    "const to = TimerOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7b3d7cd-98fd-4962-b6a7-c9afb9eda9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 3.108283\n",
      "└ @ Main In[28]:25\n",
      "┌ Warning: Slow fallback implementation invoked for conv!  You probably don't want this; check your datatypes.\n",
      "│   yT = Float64\n",
      "│   T1 = Float64\n",
      "│   T2 = Float32\n",
      "└ @ NNlib /home/araising/.julia/packages/NNlib/T3z9T/src/conv.jl:285\n",
      "┌ Info: epoch\n",
      "│   acc = 0.04\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 2.5424976\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.14\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 2.2051685\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.06\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.9256389\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.08\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.9723867\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.06\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.7991173\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.1\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.8426099\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.1\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.7898513\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.12\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.7892003\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.1\n",
      "└ @ Main In[28]:30\n",
      "┌ Info: epoch loss\n",
      "│   mean(losses) = 1.6832708\n",
      "└ @ Main In[28]:25\n",
      "┌ Info: epoch\n",
      "│   acc = 0.06\n",
      "└ @ Main In[28]:30\n"
     ]
    }
   ],
   "source": [
    "last_loss = 0;\n",
    "@timeit to \"total_training_time\" begin\n",
    "    for epoch in 1:10\n",
    "        timing_name = epoch > 1 ? \"average_epoch_training_time\" : \"train_jit\"\n",
    "\n",
    "        # Create lazily evaluated augmented training data\n",
    "        train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));\n",
    "\n",
    "        @timeit to timing_name begin\n",
    "            losses = []\n",
    "            for (x, y) in train_batches\n",
    "\n",
    "                val, grads = Flux.withgradient(model) do m\n",
    "                    # Any code inside here is differentiated.\n",
    "                    # Evaluation of the model and loss must be inside!\n",
    "                    result = m(x)\n",
    "                    sparse_logit_cross_entropy(result, y)\n",
    "                end\n",
    "                \n",
    "                # Optimiser updates parameters\n",
    "                Optimisers.update!(state, model, grads[1])\n",
    "                push!(losses, val)\n",
    "            end\n",
    "            last_loss = mean(losses)\n",
    "            @info \"epoch loss\" (mean(losses))\n",
    "        end\n",
    "        timing_name = epoch > 1 ? \"average_inference_time\" : \"eval_jit\"\n",
    "        @timeit to timing_name begin\n",
    "            acc = evaluate(model, test_loader)\n",
    "            @info \"epoch\" acc\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cf8c562-c1fa-49c5-b6bf-4c42e2c0a9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────────────────\u001b[22m\n",
       "\u001b[0m\u001b[1m                               \u001b[22m         Time                    Allocations      \n",
       "                               ───────────────────────   ────────────────────────\n",
       "       Tot / % measured:             326s /  98.8%           81.1GiB /  99.7%    \n",
       "\n",
       " Section               ncalls     time    %tot     avg     alloc    %tot      avg\n",
       " ────────────────────────────────────────────────────────────────────────────────\n",
       " total_training_time        1     323s  100.0%    323s   80.9GiB  100.0%  80.9GiB\n",
       "   average_epoch_tr...      9     173s   53.7%   19.2s   63.0GiB   77.8%  7.00GiB\n",
       "   train_jit                1     110s   34.0%    110s   13.0GiB   16.0%  13.0GiB\n",
       "   average_inferenc...      9    26.8s    8.3%   2.97s   3.52GiB    4.4%   401MiB\n",
       "   eval_jit                 1    12.9s    4.0%   12.9s   1.43GiB    1.8%  1.43GiB\n",
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────────────────\u001b[22m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2848f3e3-a8f9-4137-879b-c52ff34d9584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.234499350777778"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train time\n",
    "# Exclude jit time\n",
    "average_epoch_train_time = TimerOutputs.time(to[\"total_training_time\"][\"average_epoch_training_time\"]) / (9 * 1e9)  # Outputs in nanoseconds, conver to seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4162bb13-4c9a-46f2-b354-37a2d19cd182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1486.7419352222223"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eval batch time\n",
    "# Exclude jit time\n",
    "num_batches = length(test_loader)\n",
    "average_eval_batch_time = TimerOutputs.time(to[\"total_training_time\"][\"average_inference_time\"]) / (9 * 1e6 * num_batches)  # Outputs in nanoseconds, conver to milliseconds\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a6fea6b-85bb-4efa-9690-1ae2d40efd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_time = TimerOutputs.time(to[\"total_training_time\"]) / 1e9  # Convert nanos to seconds\n",
    "final_eval_accuracy = evaluate(model, test_loader)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa6637ab-30e0-4ca6-ae00-97a562641218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 9 entries:\n",
       "  \"task\"                         => \"classification\"\n",
       "  \"framework_name\"               => \"Flux.jl\"\n",
       "  \"final_evaluation_accuracy\"    => 0.06\n",
       "  \"total_training_time\"          => 322.589\n",
       "  \"average_epoch_training_time\"  => 19.2345\n",
       "  \"final_training_loss\"          => 1.68327\n",
       "  \"model_name\"                   => \"ResNetV2-20\"\n",
       "  \"dataset\"                      => \"CIFAR-10\"\n",
       "  \"average_batch_inference_time\" => 1486.74"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = Dict(\n",
    "    \"model_name\" => \"ResNetV2-20\",\n",
    "    \"dataset\" => \"CIFAR-10\",\n",
    "    \"framework_name\" => \"Flux.jl\",\n",
    "    \"task\" => \"classification\",\n",
    "    \"total_training_time\" => total_train_time,\n",
    "    \"average_epoch_training_time\" => average_epoch_train_time,\n",
    "    \"average_batch_inference_time\" => average_eval_batch_time,\n",
    "    \"final_training_loss\" => last_loss,\n",
    "    \"final_evaluation_accuracy\" => final_eval_accuracy\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "uw-julia-1-7-3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
