{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf850f1c-0afa-4fe7-9bae-e5afb8931698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "using MLDatasets;\n",
    "using MLUtils: DataLoader;\n",
    "using MLDataPattern;\n",
    "using ImageCore;\n",
    "using Augmentor;\n",
    "using ImageFiltering;\n",
    "using MappedArrays;\n",
    "using Random;\n",
    "using Flux: DataLoader;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afd6c4f-ec3a-4bd6-9772-f0f0cf2925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa692d0-cc2b-4967-a4db-471bd1ddaa74",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb690630-c234-4317-ba4e-2a616a90c91b",
   "metadata": {},
   "source": [
    "* Inputs: batches of (32 x 32) RGB images\n",
    "    * Tensor size (32, 32, 3, N) in WHCN dimensions\n",
    "    * Values between [0, 1]\n",
    "* For all data: ImageNet normalization\n",
    "    * Subtract means [0.485, 0.456, 0.406]\n",
    "    * Divide by standard deviations [0.229, 0.224, 0.225]\n",
    "* Augment training data only:\n",
    "    * Permute to CWHN (3, 32, 32, N)\n",
    "    * Convert to RGB image for Augmentor.jl package to process (32, 32, N)\n",
    "    * 4 pixel padding on each side (40, 40, N)\n",
    "    * Random horizontal flip\n",
    "    * (32 x 32) crop from augmented image (32, 32, N)\n",
    "    * Convert to tensors (3, 32, 32, N)\n",
    "    * Permute to WHCN (32, 32, 3, N)\n",
    "* Batch and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14c708d2-0094-402a-84f6-5e8ad1dd4358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset CIFAR10:\n",
       "  metadata  =>    Dict{String, Any} with 2 entries\n",
       "  split     =>    :test\n",
       "  features  =>    32×32×3×10000 Array{Float32, 4}\n",
       "  targets   =>    10000-element Vector{Int64}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = MLDatasets.CIFAR10(Tx=Float32, split=:train)\n",
    "test_data = MLDatasets.CIFAR10(Tx=Float32, split=:test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2530170-3449-444d-a64f-dba58b89b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 50000), (32, 32, 3, 10000))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_data.features;\n",
    "train_y = train_data.targets;\n",
    "\n",
    "test_x = test_data.features;\n",
    "test_y = test_data.targets;\n",
    "size(train_x), size(test_x)  # Data is in shape WHCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58a22570-3246-49dc-8c23-bc57c9404684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitobs (generic function with 11 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "# Copied from https://github.com/JuliaML/MLUtils.jl/blob/v0.2.11/src/splitobs.jl#L65\n",
    "# obsview doesn't work with this data, so use getobs instead\n",
    "\n",
    "import MLDataPattern.splitobs;\n",
    "\n",
    "function splitobs(data; at, shuffle::Bool=false)\n",
    "    if shuffle\n",
    "        data = shuffleobs(data)\n",
    "    end\n",
    "    n = numobs(data)\n",
    "    return map(idx -> MLDataPattern.getobs(data, idx), splitobs(n, at))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18be42de-16de-4992-ada7-cc82bf801b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 45000), (32, 32, 3, 5000))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = splitobs((train_x, train_y), at=0.9, shuffle=true);\n",
    "\n",
    "train_x, train_y = train;\n",
    "val_x, val_y = val;\n",
    "\n",
    "size(train_x), size(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c9c1a37-2a10-47a5-bbb0-aaef92e939ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the data\n",
    "\n",
    "means = reshape([0.485, 0.465, 0.406], (1, 1, 3, 1))\n",
    "stdevs = reshape([0.229, 0.224, 0.225], (1, 1, 3, 1))\n",
    "normalize(x) = (x .- means) ./ stdevs\n",
    "\n",
    "train_x = normalize(train_x);\n",
    "val_x = normalize(val_x);\n",
    "test_x = normalize(test_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d001f8e-25a0-42a9-b7f9-331d22bd555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook testing: Use less data\n",
    "train_x, train_y = MLDatasets.getobs((train_x, train_y), 1:500);\n",
    "\n",
    "val_x, val_y = MLDatasets.getobs((val_x, val_y), 1:50);\n",
    "\n",
    "test_x, test_y = MLDatasets.getobs((test_x, test_y), 1:50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9386cca-9d96-4108-a4b7-19944809dc82",
   "metadata": {},
   "source": [
    "# Data augmentation pipeline with Augmentor.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883784e-b7c1-4afb-8de3-12e746fe0fde",
   "metadata": {},
   "source": [
    "By default, batch is the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f2980d7-184d-48b6-9240-e9611efdb94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3, 500)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the training data for further augmentation\n",
    "train_x_padded = padarray(train_x, Fill(0, (4, 4, 0, 0)));  \n",
    "size(train_x_padded)  # Should be (40, 40, 3, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3fc6e65-62a6-4a88-9d6c-ce338108e160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-step Augmentor.ImmutablePipeline:\n",
       " 1.) Permute dimension order to (3, 1, 2)\n",
       " 2.) Combine color channels into colorant RGB\n",
       " 3.) Either: (50%) Flip the X axis. (50%) No operation.\n",
       " 4.) Crop random window with size (32, 32)\n",
       " 5.) Split colorant into its color channels\n",
       " 6.) Permute dimension order to (2, 3, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = PermuteDims((3, 1, 2)) |> CombineChannels(RGB) |> Either(FlipX(), NoOp()) |> RCropSize(32, 32) |> SplitChannels() |> PermuteDims((2, 3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "888cb0f7-cba7-4ee5-8383-000905dabe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an output array for augmented images\n",
    "outbatch(X) = Array{Float32}(undef, (32, 32, 3, nobs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "648c6a23-4dad-4420-a90c-d9d03aca3758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmentbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that takes a batch (images and targets) and augments the images\n",
    "augmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b19fd6e-e330-4e5b-811f-ebf77d19ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The specified values for size and/or count will result in 4 unused data points\n",
      "└ @ MLDataPattern /home/araising/.julia/packages/MLDataPattern/2yPuO/src/dataview.jl:205\n"
     ]
    }
   ],
   "source": [
    "# Shuffled and batched dataset of augmented images\n",
    "train_batch_size = 16\n",
    "\n",
    "train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "328e7811-6d67-4e16-8bb5-5c2694bf0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Validation data\n",
    "test_batch_size = 32\n",
    "\n",
    "val_loader = DataLoader((val_x, val_y), shuffle=true, batchsize=test_batch_size);\n",
    "test_loader = DataLoader((test_x, test_y), shuffle=true, batchsize=test_batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d82f1-0b52-48be-9294-4818dd193165",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D Convolution in Flux\n",
    "\n",
    "\n",
    "**Flux.Conv — Type** \n",
    "\n",
    "Conv(filter, in => out, σ = identity;\n",
    "     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init])\n",
    "\n",
    "\n",
    "Standard convolutional layer. _filter_ is a tuple of integers specifying the size of the convolutional kernel; _in_ and _out_ specify the number of input and output channels.\n",
    "\n",
    "Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a 100×100×3×1 array, and a batch of 50 would be a 100×100×3×50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5,5), a 2-tuple of integers.\n",
    "\n",
    "To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N+2, where size(x, N+1) == in is the number of input channels, and size(x, ndims(x)) is (as always) the number of observations in a batch. Then:\n",
    "\n",
    "- filter should be a tuple of N integers.\n",
    "- Keywords stride and dilation should each be either single integer, or a tuple with N integers.\n",
    "- Keyword pad specifies the number of elements added to the borders of the data array. It can be\n",
    "    - a single integer for equal padding all around,\n",
    "    - a tuple of N integers, to apply the same padding at begin/end of each spatial dimension,\n",
    "    - a tuple of 2*N integers, for asymmetric padding, or\n",
    "    - the singleton _SamePad()_, to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension.\n",
    "- Keyword groups is expected to be an Int. It specifies the number of groups to divide a convolution into.\n",
    "\n",
    "Keywords to control initialization of the layer:\n",
    "\n",
    "- init - Function used to generate initial weights. Defaults to glorot_uniform.\n",
    "- bias - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to false, or another vector can be provided such as bias = randn(Float32, out).\n",
    "            \n",
    "            \n",
    "**Flux.Conv - Method**\n",
    "_Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])_\n",
    "\n",
    "Constructs a convolutional layer with the given weight and bias. Accepts the same keywords and has the same defaults as Conv(k::NTuple{N,Integer}, ch::Pair{<:Integer,<:Integer}, σ; ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2f977-ceca-49d4-99cc-1d95fd2d83b3",
   "metadata": {},
   "source": [
    "## ResNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa38753-53a6-4b50-b94f-eb18582f1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNetLayer\n",
    "    conv1::Flux.Conv\n",
    "    conv2::Flux.Conv\n",
    "    bn1::Flux.BatchNorm\n",
    "    bn2::Flux.BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride1::Int\n",
    "    stride2::Int\n",
    "    pad1::Int\n",
    "    pad2::Int\n",
    "end\n",
    "\n",
    "# @functor ResNetLayer (conv1, conv2, bn1, bn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b343c374-5db9-4b31-81d4-824004defb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residual_identity (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride1\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        x_id = copy(x[begin:2:end, begin:2:end, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d97150-1683-4dd1-90b0-0296041562df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ResNetLayer(in_channels::Int, channels::Int; stride1=1, stride2=1, f=relu, pad1=0, pad2=0)\n",
    "    bn1 = Flux.BatchNorm(in_channels)\n",
    "    conv1 = Flux.Conv((3,3), in_channels=>channels, f; stride=stride1, pad=pad1)\n",
    "    bn2 = Flux.BatchNorm(channels)\n",
    "    conv2 = Flux.Conv((3,3), channels=>channels, f; stride=stride2, pad=pad2)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride1, stride2, pad1, pad2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097c8042-c375-430a-947f-0a9bf62f4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z)\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2640d473-1b75-4705-b8a4-269333e2eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ResNetLayer(3, 10; stride1=2, stride2=1, pad1=1, pad2=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf65a7c-2ab3-4d00-9ad4-bad8bec4b6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 10, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = randn(Float32, (64, 64, 3, 2));\n",
    "y = l(x);\n",
    "size(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52f59b-7b18-4121-8587-5f9a887c2af4",
   "metadata": {},
   "source": [
    "# Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57184ca3-bbe8-476b-9d15-f304b164297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Linear\n",
    "    W::AbstractMatrix{T} where T\n",
    "    b::AbstractVector{T} where T\n",
    "end\n",
    "\n",
    "# @functor Linear\n",
    "\n",
    "# Init\n",
    "function Linear(in_features::Int, out_features::Int)\n",
    "    k_sqrt = sqrt(1 / in_features)\n",
    "    d = Uniform(-k_sqrt, k_sqrt)\n",
    "    return Linear(rand(d, out_features, in_features), rand(d, out_features))\n",
    "end\n",
    "Linear(in_out::Pair{Int, Int}) = Linear(in_out[1], in_out[2])\n",
    "\n",
    "function Base.show(io::IO, l::Linear)\n",
    "    o, i = size(l.W)\n",
    "    print(io, \"Linear(o)\")\n",
    "end\n",
    "\n",
    "# Forward\n",
    "(l::Linear)(x::AbstractArray) where T = l.W * x .+ l.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b31ca-2a3b-4f99-8918-e61935fed1fe",
   "metadata": {},
   "source": [
    "# ResNet20 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef10f0b-b2b1-4f9b-8bb3-8ff97e2dd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNetV2\n",
    "    input_layer::Flux.Conv\n",
    "    layer_1::ResNetLayer\n",
    "    layer_2::ResNetLayer\n",
    "    layer_3::ResNetLayer\n",
    "    layer_4::ResNetLayer\n",
    "    layer_5::ResNetLayer\n",
    "    layer_6::ResNetLayer\n",
    "    layer_7::ResNetLayer\n",
    "    layer_8::ResNetLayer\n",
    "    layer_9::ResNetLayer\n",
    "    pool::GlobalMeanPool\n",
    "    linear::Linear\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00236ddf-738c-4e06-97b4-33cac90e2a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ResNetV2(in_channels::Int, num_classes::Int)\n",
    "    input_layer = Flux.Conv((3,3), in_channels=>16)\n",
    "    \n",
    "    layer_1 = ResNetLayer(16, 16)\n",
    "    layer_2 = ResNetLayer(16, 16)\n",
    "    layer_3 = ResNetLayer(16, 16)\n",
    "    \n",
    "    layer_4 = ResNetLayer(16, 32, stride1=2, stride2=1)\n",
    "    layer_5 = ResNetLayer(32, 32)\n",
    "    layer_6 = ResNetLayer(32, 32)\n",
    "    \n",
    "    layer_7 = ResNetLayer(32, 64, stride1=2, stride2=1)\n",
    "    layer_8 = ResNetLayer(64, 64)\n",
    "    layer_9 = ResNetLayer(64, 64)\n",
    "    \n",
    "    pool = GlobalMeanPool()\n",
    "    \n",
    "    linear = Linear(64, num_classes)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ResNet20(x)\n",
    "Forward function for ResNet20 model\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: 2D output tensor of shape (num classes, batch size)\n",
    "\"\"\"\n",
    "function (self::ResNetV2)(x::AbstractArray)\n",
    "    z = self.input_layer(x)\n",
    "    z = self.layer_1(z)\n",
    "    z = self.layer_2(z)\n",
    "    z = self.layer_3(z)\n",
    "    z = self.layer_4(z)\n",
    "    z = self.layer_5(z)\n",
    "    z = self.layer_6(z)\n",
    "    z = self.layer_7(z)\n",
    "    z = self.layer_8(z)\n",
    "    z = self.layer_9(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.linear(z)\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f96ab914-ed5b-4f73-b09e-d4f5988f4546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Uniform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Uniform not defined",
      "",
      "Stacktrace:",
      " [1] Linear(in_features::Int64, out_features::Int64)",
      "   @ Main ./In[12]:11",
      " [2] ResNetV2(in_channels::Int64, num_classes::Int64)",
      "   @ Main ./In[15]:18",
      " [3] top-level scope",
      "   @ In[19]:3",
      " [4] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "# Testing ResNet20 model\n",
    "# Expected output: (10, 4)\n",
    "m = ResNetV2(3, 10);\n",
    "inputs = randn(Float32, (32, 32, 3, 4))\n",
    "outputs = m(inputs);\n",
    "size(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "uw-julia-1-7-3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
