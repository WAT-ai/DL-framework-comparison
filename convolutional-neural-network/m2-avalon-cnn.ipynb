{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Yota;\n",
    "using MLDatasets;\n",
    "using NNlib;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using Functors;\n",
    "using Optimisers;\n",
    "using MLUtils: DataLoader;\n",
    "using OneHotArrays: onehotbatch\n",
    "using Metrics;\n",
    "using TimerOutputs;\n",
    "using Flux: BatchNorm, kaiming_uniform, nfan;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Conv2D\n",
    "2D convolution layer\n",
    "\n",
    "# Fields\n",
    "- `w::AbstractArray`: 4-D weight tensor for convolution kernels, of size (k1, k2, in_channels, out_channels)\n",
    "- `b::AbstractVector`: Bias for output channels\n",
    "- `use_bias::Bool`: Whether to apply bias\n",
    "\"\"\"\n",
    "mutable struct Conv2D{T}\n",
    "    w::AbstractArray{T, 4}\n",
    "    b::AbstractVector{T}\n",
    "    use_bias::Bool\n",
    "end\n",
    "\n",
    "@functor Conv2D (w, b)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Conv2D(kernel_size, in_channels, out_channels; kwargs...)\n",
    "\n",
    "Constructor for Conv2D layer\n",
    "Weights are initialized using Kaiming uniform.\n",
    "\n",
    "# Arguments\n",
    "- `kernel_size::Tuple{Int, Int}`: 2-tuple of int for convolution kernel size\n",
    "- `in_channels::Int`: Number of input channels to the convolution layer\n",
    "- `out_channels::Int`: Number of output channels from the convolution layer\n",
    "\n",
    "# Keywords\n",
    "- `bias::Bool`: Whether to have a bias during convolution, by default false\n",
    "\n",
    "# Returns\n",
    "- `Conv2D`: Initialized Conv2D struct\n",
    "\"\"\"\n",
    "function Conv2D(kernel_size::Tuple{Int, Int}, in_channels::Int, out_channels::Int;\n",
    "    bias::Bool=false)\n",
    "    w_size = (kernel_size..., in_channels, out_channels)\n",
    "    w = kaiming_uniform(w_size...)\n",
    "    (fan_in, fan_out) = nfan(w_size)\n",
    "    \n",
    "    if bias\n",
    "        # Init bias with fan_in from weights. Use gain = √2 for ReLU\n",
    "        bound = √3 * √2 / √fan_in\n",
    "        rng = Uniform(-bound, bound)\n",
    "        b = rand(rng, out_channels, Float32)\n",
    "    else\n",
    "        b = zeros(Float32, out_channels)\n",
    "    end\n",
    "\n",
    "    return Conv2D(w, b, bias)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Conv2D(x; kwargs...)\n",
    "\n",
    "Perform 2D convolution using initialized layer\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Keywords\n",
    "- `stride::Int`: convolution stride, by default 1\n",
    "- `pad::Int`: amount of padding on each side, by default 0\n",
    "- `dilation::Int`: convolution dialation, by default 1\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: Output 4D image tensor\n",
    "\"\"\"\n",
    "function (self::Conv2D)(x::AbstractArray; stride::Int=1, pad::Int=0, dilation::Int=1)\n",
    "    y = conv(x, self.w; stride=stride, pad=pad, dilation=dilation)\n",
    "    if self.use_bias\n",
    "        # Bias is applied channel-wise\n",
    "        (w, h, c, b) = size(y)\n",
    "        bias = reshape(self.b, (1, 1, c, 1))\n",
    "        y = y .+ bias\n",
    "    end\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ResNetLayer\n",
    "ResNetV2 Layer\n",
    "See \"Identity Mappings in Deep Residual Networks\", https://arxiv.org/pdf/1603.05027.pdf\n",
    "\n",
    "# Fields\n",
    "- `conv1::Conv2D`: First convolution layer\n",
    "- `conv2::Conv2D`: Second convolution layer\n",
    "- `bn1::BatchNorm`: First batch norm layer\n",
    "- `bn2::BatchNorm`: Second batchnorm layer\n",
    "- `f::Function`: Activation function\n",
    "- `in_channels::Int`: Number of input channels to the layer\n",
    "- `channels::Int`: Number of channels used throughout the layer\n",
    "- `stride::Int`: Stride to apply to first convolution layer\n",
    "\"\"\"\n",
    "mutable struct ResNetLayer\n",
    "    conv1::Conv2D\n",
    "    conv2::Conv2D\n",
    "    bn1::BatchNorm\n",
    "    bn2::BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride::Int\n",
    "end\n",
    "\n",
    "@functor ResNetLayer (conv1, conv2, bn1, bn2)\n",
    "\n",
    "\"\"\"\n",
    "    residual_identity(ResNetLayer, x)\n",
    "Identity function for computing identity connection after a strided convolution\n",
    "Downsamples `x` by a factor of `stride` and adds extra channels filled with zeros\n",
    "\n",
    "# Arguments\n",
    "- `layer::ResNetLayer`: ResNetLayer struct that has information about stride and channels\n",
    "- `x::AbstractArray`: Input tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `x_id::AbstractArray`: Downsampled identity tensor\n",
    "\"\"\"\n",
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        x_id = copy(x[begin:2:end, begin:2:end, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ResNetLayer(in_channels, channels; kwargs...)\n",
    "Constructor for ResNetLayer\n",
    "\n",
    "# Arguments\n",
    "- `in_channels::Int`: Number of input channels to the layer\n",
    "- `channels::Int`: Number of channels used throughout the layer\n",
    "\n",
    "# Keywords\n",
    "- `stride::Int`: Stride to apply in first convolution layer\n",
    "- `f::Function`: Activation function to apply, by default relu\n",
    "\n",
    "# Returns\n",
    "- `ResNetLayer`: Initialized ResNetLayer\n",
    "\"\"\"\n",
    "function ResNetLayer(in_channels::Int, channels::Int; stride=1, f=relu)\n",
    "    bn1 = BatchNorm(in_channels)\n",
    "    conv1 = Conv2D((3, 3), in_channels, channels, bias=false)\n",
    "    bn2 = BatchNorm(channels)\n",
    "    conv2 = Conv2D((3, 3), channels, channels, bias=false)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    ResNetLayer(x)\n",
    "\n",
    "Forward function for ResNetLayer\n",
    "Applies stride in first convolution for downsampling\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: 4D output image tensor\n",
    "\"\"\"\n",
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z; pad=1, stride=self.stride)  # pad=1 will keep same size with (3x3) kernel\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z; pad=1)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ResNetLayer(3, 10; stride=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 10, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = randn(Float32, (64, 64, 3, 2));\n",
    "y = l(x);\n",
    "size(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
