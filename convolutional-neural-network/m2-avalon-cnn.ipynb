{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "using MLDatasets;\n",
    "using MLUtils: DataLoader;\n",
    "using MLDataPattern;\n",
    "using ImageCore;\n",
    "using Augmentor;\n",
    "using ImageFiltering;\n",
    "using MappedArrays;\n",
    "using Random;\n",
    "using Flux: DataLoader;\n",
    "# using OneHotArrays: onehotbatch\n",
    "\n",
    "# Model creation\n",
    "using NNlib;\n",
    "using Flux: BatchNorm, Chain, GlobalMeanPool, kaiming_uniform, nfan;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using Functors;\n",
    "\n",
    "# Training\n",
    "# using Yota;\n",
    "using Zygote;\n",
    "using Optimisers;\n",
    "using Metrics;\n",
    "using TimerOutputs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Primitives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3x3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Conv3x3\n",
    "2D convolution layer with 3x3 kernel for ResNet\n",
    "\n",
    "# Fields\n",
    "- `w::AbstractArray`: 4-D weight tensor for convolution kernels, of size (k1, k2, in_channels, out_channels)\n",
    "- `b::AbstractVector`: Bias for output channels\n",
    "- `use_bias::Bool`: Whether to apply bias\n",
    "- `stride::Int`: Stride to apply in convolution\n",
    "- `padding::Int`: Padding to apply in convolution\n",
    "\"\"\"\n",
    "mutable struct Conv3x3{T}\n",
    "    w::AbstractArray{T, 4}\n",
    "    b::AbstractVector{T}\n",
    "    use_bias::Bool\n",
    "    stride::Int\n",
    "    padding::Int\n",
    "end\n",
    "\n",
    "@functor Conv3x3 (w, b)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Conv3x3(in_channels, out_channels; kwargs...)\n",
    "\n",
    "Constructor for Conv3x3 layer\n",
    "Weights are initialized using Kaiming uniform.\n",
    "\n",
    "# Arguments\n",
    "- `in_channels::Int`: Number of input channels to the convolution layer\n",
    "- `out_channels::Int`: Number of output channels from the convolution layer\n",
    "\n",
    "# Keywords\n",
    "- `bias::Bool`: Whether to have a bias during convolution, by default false\n",
    "- `stride::Int`: Stride to apply in convolution, by default 1\n",
    "- `padding::Int`: Padding to apply in convolution, by default 1 (\"same\" padding)\n",
    "\n",
    "# Returns\n",
    "- `Conv3x3`: Initialized Conv3x3 struct\n",
    "\"\"\"\n",
    "function Conv3x3(in_channels::Int, out_channels::Int; bias::Bool=false, stride::Int=1, padding::Int=1)\n",
    "    w_size = (3, 3, in_channels, out_channels)\n",
    "    w = kaiming_uniform(w_size...)\n",
    "    (fan_in, fan_out) = nfan(w_size)\n",
    "    \n",
    "    if bias\n",
    "        # Init bias with fan_in from weights. Use gain = √2 for ReLU\n",
    "        bound = √3 * √2 / √fan_in\n",
    "        rng = Uniform(-bound, bound)\n",
    "        b = rand(rng, out_channels, Float32)\n",
    "    else\n",
    "        b = zeros(Float32, out_channels)\n",
    "    end\n",
    "\n",
    "    return Conv3x3(w, b, bias, stride, padding)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Conv3x3(x; kwargs...)\n",
    "\n",
    "Perform 2D convolution using initialized layer\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: Output 4D image tensor\n",
    "\"\"\"\n",
    "function (self::Conv3x3)(x::AbstractArray)\n",
    "    y = conv(x, self.w; stride=self.stride, pad=self.padding)\n",
    "    if self.use_bias\n",
    "        # Bias is applied channel-wise\n",
    "        (w, h, c, b) = size(y)\n",
    "        bias = reshape(self.b, (1, 1, c, 1))\n",
    "        y = y .+ bias\n",
    "    end\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 10, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Conv3x3\n",
    "# Expected output: (16, 16, 10, 4)\n",
    "\n",
    "inputs = randn(Float32, 32, 32, 3, 4)\n",
    "c = Conv3x3(3, 10; stride=2)\n",
    "\n",
    "outputs = c(inputs);\n",
    "size(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ResNetLayer\n",
    "ResNetV2 Layer\n",
    "See \"Identity Mappings in Deep Residual Networks\", https://arxiv.org/pdf/1603.05027.pdf\n",
    "\n",
    "# Fields\n",
    "- `conv1::Conv3x3`: First convolution layer\n",
    "- `conv2::Conv3x3`: Second convolution layer\n",
    "- `bn1::BatchNorm`: First batch norm layer\n",
    "- `bn2::BatchNorm`: Second batchnorm layer\n",
    "- `f::Function`: Activation function\n",
    "- `in_channels::Int`: Number of input channels to the layer\n",
    "- `channels::Int`: Number of channels used throughout the layer\n",
    "- `stride::Int`: Stride to apply to first convolution layer\n",
    "\"\"\"\n",
    "mutable struct ResNetLayer\n",
    "    conv1::Conv3x3\n",
    "    conv2::Conv3x3\n",
    "    bn1::BatchNorm\n",
    "    bn2::BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride::Int\n",
    "end\n",
    "\n",
    "@functor ResNetLayer (conv1, conv2, bn1, bn2)\n",
    "\n",
    "\"\"\"\n",
    "    residual_identity(ResNetLayer, x)\n",
    "Identity function for computing identity connection after a strided convolution\n",
    "Downsamples `x` by a factor of `stride` and adds extra channels filled with zeros\n",
    "\n",
    "# Arguments\n",
    "- `layer::ResNetLayer`: ResNetLayer struct that has information about stride and channels\n",
    "- `x::AbstractArray`: Input tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `x_id::AbstractArray`: Downsampled identity tensor\n",
    "\"\"\"\n",
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        inds = CartesianIndices((1:stride:w, 1:stride:h))\n",
    "        x_id = copy(x[inds, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(T, w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ResNetLayer(in_channels, channels; kwargs...)\n",
    "Constructor for ResNetLayer\n",
    "\n",
    "# Arguments\n",
    "- `in_channels::Int`: Number of input channels to the layer\n",
    "- `channels::Int`: Number of channels used throughout the layer\n",
    "\n",
    "# Keywords\n",
    "- `stride::Int`: Stride to apply in first convolution layer\n",
    "- `f::Function`: Activation function to apply, by default relu\n",
    "\n",
    "# Returns\n",
    "- `ResNetLayer`: Initialized ResNetLayer\n",
    "\"\"\"\n",
    "function ResNetLayer(in_channels::Int, channels::Int; stride=1, f=relu)\n",
    "    bn1 = BatchNorm(in_channels)\n",
    "    conv1 = Conv3x3(in_channels, channels; bias=false, stride=stride)\n",
    "    bn2 = BatchNorm(channels)\n",
    "    conv2 = Conv3x3(channels, channels; bias=false)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    ResNetLayer(x)\n",
    "\n",
    "Forward function for ResNetLayer\n",
    "Applies stride in first convolution for downsampling\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: 4D output image tensor\n",
    "\"\"\"\n",
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z)\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 10, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing ResNetLayer\n",
    "# Expected output: (16, 61, 10, 4)\n",
    "\n",
    "l = ResNetLayer(3, 10; stride=2);\n",
    "x = randn(Float32, (32, 32, 3, 4));\n",
    "y = l(x);\n",
    "size(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Linear\n",
    "    W::AbstractMatrix{T} where T\n",
    "    b::AbstractVector{T} where T\n",
    "end\n",
    "\n",
    "@functor Linear\n",
    "\n",
    "# Init\n",
    "function Linear(in_features::Int, out_features::Int)\n",
    "    k_sqrt = sqrt(1 / in_features)\n",
    "    d = Uniform(-k_sqrt, k_sqrt)\n",
    "    return Linear(rand(d, out_features, in_features), rand(d, out_features))\n",
    "end\n",
    "Linear(in_out::Pair{Int, Int}) = Linear(in_out[1], in_out[2])\n",
    "\n",
    "function Base.show(io::IO, l::Linear)\n",
    "    o, i = size(l.W)\n",
    "    print(io, \"Linear($i=>$o)\")\n",
    "end\n",
    "\n",
    "# Forward\n",
    "(l::Linear)(x::AbstractArray) where T = l.W * x .+ l.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet20Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ResNet20\n",
    "ResNetV2-20 Model\n",
    "See section Section 4.2 of \"Deep Residual Learning for Image Recognition\" (https://arxiv.org/pdf/1512.03385.pdf) \n",
    "for architecture details.\n",
    "\n",
    "# Fields\n",
    "- `input_conv::Conv3x3`: First layer convolution\n",
    "- `resnet_blocks::Chain`: Chain of ResNet V2 blocks\n",
    "- `pool::GlobalMeanPool`: Global average pooling\n",
    "- `linear::Linear`: Linear classifier layer\n",
    "\"\"\"\n",
    "mutable struct ResNet20\n",
    "    input_conv::Conv3x3\n",
    "    resnet_blocks::Chain\n",
    "    pool::GlobalMeanPool\n",
    "    linear::Linear\n",
    "end\n",
    "\n",
    "@functor ResNet20\n",
    "\n",
    "\"\"\"\n",
    "    ResNet20(in_channels, num_classes)\n",
    "Constructor for ResNet20 model\n",
    "\n",
    "# Arguments\n",
    "- `in_channels::Int`: Number of input channels to the model\n",
    "- `num_classes::Int`: Number of classes to output\n",
    "\n",
    "# Returns\n",
    "- `ResNet20`: Initialized model\n",
    "\"\"\"\n",
    "function ResNet20(in_channels::Int, num_classes::Int)\n",
    "    resnet_blocks = Chain(\n",
    "        block_1 = ResNetLayer(16, 16),\n",
    "        block_2 = ResNetLayer(16, 16),\n",
    "        block_3 = ResNetLayer(16, 16),\n",
    "        block_4 = ResNetLayer(16, 32; stride=2),\n",
    "        block_5 = ResNetLayer(32, 32),\n",
    "        block_6 = ResNetLayer(32, 32),\n",
    "        block_7 = ResNetLayer(32, 64; stride=2),\n",
    "        block_8 = ResNetLayer(64, 64),\n",
    "        block_9 = ResNetLayer(64, 64)\n",
    "    )\n",
    "    return ResNet20(\n",
    "        Conv3x3(in_channels, 16; bias=false),\n",
    "        resnet_blocks,\n",
    "        GlobalMeanPool(),\n",
    "        Linear(64, num_classes)\n",
    "    )\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ResNet20(x)\n",
    "Forward function for ResNet20 model\n",
    "\n",
    "# Arguments\n",
    "- `x::AbstractArray`: 4D input image tensor of shape (width, height, channels, batch size)\n",
    "\n",
    "# Returns\n",
    "- `y::AbstractArray`: 2D output tensor of shape (num classes, batch size)\n",
    "\"\"\"\n",
    "function (self::ResNet20)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_blocks(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.linear(z)\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing ResNet20 model\n",
    "# Expected output: (10, 4)\n",
    "m = ResNet20(3, 10);\n",
    "inputs = randn(Float32, (32, 32, 3, 4))\n",
    "outputs = m(inputs);\n",
    "size(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "- Inputs: batches of (32 x 32) RGB images\n",
    "    - Tensor size (32, 32, 3, N) in WHCN dimensions\n",
    "    - Values between [0, 1]\n",
    "- For all data: ImageNet normalization\n",
    "    - Subtract means [0.485, 0.456, 0.406]\n",
    "    - Divide by standard deviations [0.229, 0.224, 0.225]\n",
    "- Augment training data only:\n",
    "    - Permute to CWHN (3, 32, 32, N)\n",
    "    - Convert to RGB image for Augmentor.jl package to process (32, 32, N)\n",
    "    - 4 pixel padding on each side (40, 40, N)\n",
    "    - Random horizontal flip\n",
    "    - (32 x 32) crop from augmented image (32, 32, N)\n",
    "    - Convert to tensors (3, 32, 32, N)\n",
    "    - Permute to WHCN (32, 32, 3, N)\n",
    "- Batch and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset CIFAR10:\n",
       "  metadata  =>    Dict{String, Any} with 2 entries\n",
       "  split     =>    :test\n",
       "  features  =>    32×32×3×10000 Array{Float32, 4}\n",
       "  targets   =>    10000-element Vector{Int64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = MLDatasets.CIFAR10(Tx=Float32, split=:train)\n",
    "test_data = MLDatasets.CIFAR10(Tx=Float32, split=:test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 50000), (32, 32, 3, 10000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_data.features;\n",
    "train_y = train_data.targets;\n",
    "\n",
    "test_x = test_data.features;\n",
    "test_y = test_data.targets;\n",
    "size(train_x), size(test_x)  # Data is in shape WHCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitobs (generic function with 11 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "# Copied from https://github.com/JuliaML/MLUtils.jl/blob/v0.2.11/src/splitobs.jl#L65\n",
    "# obsview doesn't work with this data, so use getobs instead\n",
    "\n",
    "import MLDataPattern.splitobs;\n",
    "\n",
    "function splitobs(data; at, shuffle::Bool=false)\n",
    "    if shuffle\n",
    "        data = shuffleobs(data)\n",
    "    end\n",
    "    n = numobs(data)\n",
    "    return map(idx -> MLDataPattern.getobs(data, idx), splitobs(n, at))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 3, 45000), (32, 32, 3, 5000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = splitobs((train_x, train_y), at=0.9, shuffle=true);\n",
    "\n",
    "train_x, train_y = train;\n",
    "val_x, val_y = val;\n",
    "\n",
    "size(train_x), size(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the data\n",
    "\n",
    "means = reshape([0.485, 0.465, 0.406], (1, 1, 3, 1))\n",
    "stdevs = reshape([0.229, 0.224, 0.225], (1, 1, 3, 1))\n",
    "normalize(x) = (x .- means) ./ stdevs\n",
    "\n",
    "train_x = normalize(train_x);\n",
    "val_x = normalize(val_x);\n",
    "test_x = normalize(test_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook testing: Use less data\n",
    "train_x, train_y = MLDatasets.getobs((train_x, train_y), 1:500);\n",
    "\n",
    "val_x, val_y = MLDatasets.getobs((val_x, val_y), 1:50);\n",
    "\n",
    "test_x, test_y = MLDatasets.getobs((test_x, test_y), 1:50);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation pipeline with Augmentor.jl\n",
    "By default, batch is the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3, 500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the training data for further augmentation\n",
    "train_x_padded = padarray(train_x, Fill(0, (4, 4, 0, 0)));  \n",
    "size(train_x_padded)  # Should be (40, 40, 3, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-step Augmentor.ImmutablePipeline:\n",
       " 1.) Permute dimension order to (3, 1, 2)\n",
       " 2.) Combine color channels into colorant RGB\n",
       " 3.) Either: (50%) Flip the X axis. (50%) No operation.\n",
       " 4.) Crop random window with size (32, 32)\n",
       " 5.) Split colorant into its color channels\n",
       " 6.) Permute dimension order to (2, 3, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = PermuteDims((3, 1, 2)) |> CombineChannels(RGB) |> Either(FlipX(), NoOp()) |> RCropSize(32, 32) |> SplitChannels() |> PermuteDims((2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an output array for augmented images\n",
    "outbatch(X) = Array{Float32}(undef, (32, 32, 3, nobs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmentbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that takes a batch (images and targets) and augments the images\n",
    "augmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The specified values for size and/or count will result in 4 unused data points\n",
      "└ @ MLDataPattern /Users/trevoryu/.julia/packages/MLDataPattern/2yPuO/src/dataview.jl:205\n"
     ]
    }
   ],
   "source": [
    "# Shuffled and batched dataset of augmented images\n",
    "train_batch_size = 16\n",
    "\n",
    "train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Validation data\n",
    "test_batch_size = 32\n",
    "\n",
    "val_loader = DataLoader((val_x, val_y), shuffle=true, batchsize=test_batch_size);\n",
    "test_loader = DataLoader((test_x, test_y), shuffle=true, batchsize=test_batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Cross Entropy function\n",
    "Extend logit cross entropy to work efficiently with sparse labels (i.e. integer indices and not one-hot labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse_logit_cross_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    sparse_logit_cross_entropy(logits, labels)\n",
    "\n",
    "Efficient computation of cross entropy loss with model logits and integer indices as labels.\n",
    "Integer indices are from [0,  N-1], where N is the number of classes\n",
    "Similar to TensorFlow SparseCategoricalCrossEntropy\n",
    "\n",
    "# Arguments\n",
    "- `logits::AbstractArray`: 2D model logits tensor of shape (classes, batch size)\n",
    "- `labels::AbstractArray`: 1D integer label indices of shape (batch size,)\n",
    "\n",
    "# Returns\n",
    "- `loss::Float32`: Cross entropy loss\n",
    "\"\"\"\n",
    "# function sparse_logit_cross_entropy(logits, labels)\n",
    "#     log_probs = logsoftmax(logits);\n",
    "#     # Select indices of labels for loss\n",
    "#     log_probs = map((x, i) -> x[i + 1], eachslice(log_probs; dims=2), labels);\n",
    "#     loss = -mean(log_probs);\n",
    "#     return loss\n",
    "# end\n",
    "\n",
    "function sparse_logit_cross_entropy(logits, labels)\n",
    "    log_probs = logsoftmax(logits);\n",
    "    inds = CartesianIndex.(labels .+ 1, axes(log_probs, 2));\n",
    "    # Select indices of labels for loss\n",
    "    log_probs = log_probs[inds];\n",
    "    loss = -mean(log_probs);\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with 3 input channels and 10 classes\n",
    "model = ResNet20(3, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup AdamW optimizer\n",
    "β = (0.9, 0.999);\n",
    "decay = 1e-4;\n",
    "state = Optimisers.setup(Optimisers.Adam(1e-3, β, decay), model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create objective function to optimize\n",
    "function loss_function(model::ResNet20, x::AbstractArray, y::AbstractArray)\n",
    "    ŷ = model(x)\n",
    "    loss = sparse_logit_cross_entropy(ŷ, y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y) = first(train_batches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, g = grad(loss_function, model, x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 2 methods)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct ResNet5\n",
    "    input_conv::Conv3x3\n",
    "    resnet_block::ResNetLayer\n",
    "    pool::GlobalMeanPool\n",
    "    linear::Linear\n",
    "end\n",
    "\n",
    "@functor ResNet5\n",
    "\n",
    "function ResNet5(in_channels::Int, num_classes::Int)\n",
    "    return ResNet5(\n",
    "        Conv3x3(in_channels, 16; bias=false),\n",
    "        ResNetLayer(16, 16),\n",
    "        GlobalMeanPool(),\n",
    "        Linear(16, num_classes)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (self::ResNet5)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_block(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.linear(z)\n",
    "    return y\n",
    "end\n",
    "\n",
    "\n",
    "function loss_function(model::ResNet5, x::AbstractArray, y::AbstractArray)\n",
    "    ŷ = model(x)\n",
    "    loss = sparse_logit_cross_entropy(ŷ, y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yota is unable to compute gradients through the ResNet for some reason, maybe due to residual connections?\n",
    "# loss, g = grad(loss_function, model, x, y)\n",
    "model = ResNet5(3, 10);\n",
    "\n",
    "loss, g = Zygote.gradient(loss_function, model, x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×32×3×16 Array{Float32, 4}:\n",
       "[:, :, 1, 1] =\n",
       "  3.02599f-5   7.07849f-5   7.94292f-5   …  6.81889f-5   4.79578f-5\n",
       "  1.98297f-5   1.765f-5     3.06098f-5      5.32691f-5   1.61127f-5\n",
       "  2.41994f-5  -6.55991f-6   2.34102f-5      5.13781f-5   3.09528f-5\n",
       " -1.93668f-5   1.05649f-5   3.49399f-5      6.30373f-5   4.09379f-5\n",
       "  1.10981f-5  -9.92099f-6  -1.78859f-5      4.04262f-5   2.8198f-5\n",
       "  2.52191f-5  -7.15537f-6  -1.00885f-5   …  4.56546f-5   2.18946f-5\n",
       " -2.06225f-6   6.24625f-6   4.01926f-7      5.5654f-5    1.91564f-5\n",
       "  6.59202f-5   5.37844f-5   4.03756f-5      2.97683f-5   2.18327f-5\n",
       "  5.54791f-5  -1.35512f-5  -5.49614f-6      6.7599f-5    2.30759f-5\n",
       "  1.27065f-5   4.77054f-5   3.88314f-5      6.97576f-5   1.83329f-5\n",
       " -1.4598f-5    6.17554f-5   6.25489f-5   …  3.87517f-5  -1.14439f-5\n",
       "  7.20194f-6   4.24674f-5   6.32658f-5      4.78324f-5  -1.47931f-5\n",
       "  3.15358f-6  -2.03658f-6   7.06585f-5      4.49833f-5  -2.59674f-5\n",
       "  ⋮                                      ⋱  ⋮           \n",
       "  5.2263f-5   -4.50647f-5  -2.25127f-5   …  9.51665f-5   4.4f-5\n",
       "  1.61594f-5  -3.3482f-7    0.000104181     2.9485f-5    4.4071f-5\n",
       "  1.25363f-6   7.75058f-5   9.14233f-5      5.4606f-5    2.82694f-5\n",
       " -3.11704f-6   3.85014f-5   5.83288f-5      3.74321f-5   1.13333f-5\n",
       "  5.29375f-6  -1.05679f-5   9.192f-5        4.24467f-5   1.05282f-5\n",
       "  2.21775f-5   6.68014f-5   5.31901f-5   …  2.68893f-5   1.18964f-5\n",
       "  2.60966f-5   7.92719f-5  -1.81391f-6      1.23706f-5  -5.72784f-6\n",
       "  6.58447f-5   9.22514f-5   1.79052f-5      4.21509f-5  -6.20041f-6\n",
       "  4.01423f-5   2.70646f-6   1.12668f-5      4.01417f-5  -2.46894f-5\n",
       "  2.14469f-5   9.9932f-6    2.50804f-6      2.68699f-5  -1.75322f-5\n",
       "  2.43846f-5  -3.50285f-5  -1.4009f-5    …  1.2248f-5   -2.96704f-5\n",
       "  3.65423f-5   3.62764f-5   1.54451f-5      5.0854f-5   -2.20522f-5\n",
       "\n",
       "[:, :, 2, 1] =\n",
       "  3.76992f-5  7.48702f-6  -2.81303f-6  …   1.812f-5     1.04432f-5\n",
       "  5.79607f-5  2.71987f-5   5.03026f-5      7.14545f-5  -3.38673f-7\n",
       "  7.87394f-5  2.4923f-5    5.47301f-5      5.71312f-5   1.61651f-5\n",
       "  3.8435f-5   6.15371f-5  -6.29293f-6      2.40774f-6  -1.11485f-5\n",
       "  4.79497f-5  6.89749f-5   5.8922f-5       4.96105f-5   1.32421f-5\n",
       "  5.28648f-5  3.94974f-5   4.60777f-5  …   4.10631f-5   1.3505f-5\n",
       "  4.97679f-5  4.88632f-6   1.43664f-5      4.74429f-5   6.08603f-6\n",
       "  2.36455f-5  9.7437f-7    1.80196f-5      2.40811f-5  -7.12798f-6\n",
       "  5.48978f-5  6.9915f-5    4.14253f-5      2.9634f-5   -5.08709f-5\n",
       "  6.85393f-5  3.47892f-5   7.1222f-7      -5.1274f-6   -2.73478f-5\n",
       "  9.60008f-5  3.47619f-5   7.07801f-5  …   7.87388f-7  -1.79925f-5\n",
       "  7.72216f-5  4.29089f-5   2.99073f-5      1.36177f-5  -1.39108f-5\n",
       "  5.51521f-5  6.30509f-5   2.48335f-5     -1.26737f-5  -1.63436f-5\n",
       "  ⋮                                    ⋱   ⋮           \n",
       "  5.42912f-5  7.96865f-5   8.22031f-5  …   3.19467f-5  -8.60486f-6\n",
       "  7.68046f-5  5.5777f-5    2.9119f-5       4.10963f-6   9.73342f-6\n",
       "  7.39428f-5  3.57019f-5   4.50378f-5      4.44304f-5   5.60511f-6\n",
       "  5.39866f-5  5.74287f-5   5.35382f-5      6.33111f-5   1.34331f-5\n",
       "  4.28429f-5  8.33516f-5   2.37104f-5      5.19725f-5   1.33247f-5\n",
       "  6.13821f-5  8.70705f-5   1.30849f-5  …   4.76452f-5   1.92637f-5\n",
       "  7.69637f-5  2.95067f-5   5.01393f-5      5.92221f-5  -5.69754f-6\n",
       "  7.06622f-5  3.78045f-5   2.57455f-5      6.01862f-5  -3.20673f-5\n",
       "  9.21895f-5  8.49217f-6   1.16602f-5      2.54226f-5  -1.83032f-5\n",
       "  4.93875f-5  4.78141f-5  -4.77894f-6      2.70293f-5  -2.938f-5\n",
       "  5.14772f-5  4.37836f-5   8.34171f-6  …   3.19581f-5  -2.37195f-5\n",
       " -2.98773f-6  8.02027f-6   8.40784f-6     -4.09671f-6  -2.94129f-5\n",
       "\n",
       "[:, :, 3, 1] =\n",
       "  1.2862f-6    4.77207f-7  -1.57079f-5  …   1.04441f-5   2.27455f-5\n",
       "  2.75242f-5  -5.33371f-5  -4.94791f-5     -1.09049f-5  -1.99607f-5\n",
       "  5.19087f-5   2.7829f-5    3.21663f-5      2.53924f-5  -1.38178f-5\n",
       " -2.53956f-5  -2.63433f-5  -6.79972f-6      1.73855f-5  -2.59691f-6\n",
       "  1.12384f-5   4.32526f-7  -2.09f-5         3.17825f-5  -4.35946f-5\n",
       "  6.22647f-5   5.02201f-5   7.55198f-5  …   6.31574f-5  -3.14061f-5\n",
       "  3.12558f-5   5.58974f-6   3.55387f-5      7.12204f-5  -4.39164f-5\n",
       "  1.5551f-5   -8.77087f-6  -1.23173f-5      3.49208f-5  -3.57157f-5\n",
       "  4.719f-5     3.91821f-5   3.5528f-5       3.21446f-5   2.54934f-6\n",
       "  1.25547f-5  -4.20974f-6   1.70793f-5      2.65614f-5  -1.06939f-5\n",
       "  5.12548f-5  -3.61f-5     -8.14601f-6  …   4.12959f-5  -8.88922f-6\n",
       "  3.26542f-5   7.27325f-6  -1.63632f-5      2.82823f-5  -1.83601f-5\n",
       "  4.72683f-5   5.56875f-6  -2.15725f-5      2.85912f-5  -1.15224f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  4.61032f-5   2.65637f-5   1.50223f-5  …   1.80717f-5  -3.08001f-5\n",
       "  5.46204f-5  -2.88446f-5  -9.91724f-6      4.66182f-5  -4.1874f-5\n",
       "  1.76614f-5  -4.24483f-5   1.39927f-6      3.69276f-5  -2.28269f-5\n",
       "  1.65664f-5   1.76319f-5  -7.31237f-6      8.13584f-5  -3.76405f-5\n",
       "  2.78869f-5  -2.22517f-5  -2.26075f-5      5.80412f-5  -3.49975f-5\n",
       " -5.57708f-6  -2.66414f-5  -3.51803f-6  …   6.17705f-5  -3.39336f-5\n",
       "  1.4627f-5   -8.79313f-6  -2.38622f-6      8.02763f-5  -2.54095f-5\n",
       "  1.83504f-5  -2.5315f-5    2.72489f-5      7.86559f-5  -1.8537f-5\n",
       "  3.9976f-5    1.55974f-5   2.68715f-5      5.16441f-5  -9.81236f-6\n",
       "  9.07996f-6  -9.89995f-6   3.99275f-5      4.87765f-5  -2.42536f-5\n",
       "  3.81326f-5   3.13464f-5   4.95222f-6  …   1.43746f-5  -2.19342f-5\n",
       "  4.47261f-5   5.06885f-5   5.17048f-5      3.6359f-5   -1.015f-5\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " -5.1715f-5   -3.97466f-5   -4.17877f-5   …  -8.59199f-5   -6.29779f-5\n",
       " -4.34385f-5  -0.000102285  -0.000143717     -9.24608f-5   -6.79693f-5\n",
       " -5.16411f-5  -7.6439f-5    -7.21858f-5      -7.15868f-5   -6.4003f-5\n",
       " -6.37645f-5  -4.10971f-5   -6.77312f-5       1.28115f-5   -5.67238f-5\n",
       " -5.2982f-5   -6.01114f-5   -4.75445f-5      -6.94254f-5   -4.52355f-5\n",
       " -3.67806f-6  -5.51662f-5    7.77226f-6   …  -0.000111437  -5.9081f-5\n",
       " -4.01633f-5  -0.00010131   -2.79517f-5      -3.02946f-5   -9.26742f-5\n",
       " -5.29171f-5  -0.000123709  -6.55998f-5      -2.28297f-5   -4.61426f-5\n",
       " -4.04387f-5  -0.000104736  -5.94859f-5      -0.000101024  -5.27527f-5\n",
       " -2.29038f-5  -6.72127f-5   -3.16275f-5      -7.22922f-5   -7.28352f-5\n",
       " -4.76548f-5  -6.43781f-5   -4.53364f-5   …   1.02282f-5   -6.64914f-5\n",
       " -4.43974f-5  -6.91679f-5   -4.18218f-5       1.78923f-5   -6.05302f-5\n",
       " -3.80435f-5  -6.33752f-5   -3.99741f-5      -2.71114f-5   -3.74952f-5\n",
       "  ⋮                                       ⋱   ⋮            \n",
       " -3.5364f-5   -5.42763f-5   -3.10102f-5   …  -3.44157f-5   -4.42077f-5\n",
       " -2.43917f-5  -8.61071f-5   -7.32378f-5      -0.000142503  -3.29022f-5\n",
       " -1.8325f-5   -6.75871f-5   -5.89176f-5      -0.000145996  -5.71793f-5\n",
       " -5.3524f-5   -8.31187f-5   -7.59985f-5      -9.66343f-5   -6.66737f-5\n",
       " -4.76738f-5  -6.83498f-5   -6.56073f-5      -6.53959f-5   -7.36888f-5\n",
       " -6.86573f-5  -6.953f-5     -7.29586f-5   …  -6.91815f-5   -6.42754f-5\n",
       " -6.16797f-5  -7.40165f-5   -6.76492f-5      -5.988f-5     -7.78888f-5\n",
       " -2.50485f-5  -4.0817f-5    -7.54074f-5      -4.76968f-5   -5.94447f-5\n",
       " -4.34165f-5  -6.43772f-5   -6.06265f-5      -6.87237f-5   -4.45653f-5\n",
       " -5.0457f-5   -3.406f-5     -3.45667f-5      -8.40455f-5   -5.55188f-5\n",
       " -4.44595f-5  -7.82585f-5   -7.0952f-5    …  -2.71737f-5   -2.14214f-5\n",
       " -7.3095f-5   -6.37947f-5   -7.5643f-5       -8.92044f-5   -4.3105f-5\n",
       "\n",
       "[:, :, 2, 2] =\n",
       " -1.07738f-5   1.71373f-5   4.73048f-5  …   5.24074f-5  -2.05023f-5\n",
       " -4.28161f-6   3.95549f-5   8.64042f-5      4.1219f-5   -3.25393f-6\n",
       "  6.81199f-6   6.04836f-5   5.84807f-5      4.19532f-7  -8.95609f-6\n",
       "  9.14169f-6   3.29411f-5   1.28505f-5     -5.64335f-5  -3.09161f-5\n",
       " -1.84307f-5  -2.08017f-5   1.93858f-5     -5.5322f-5   -7.13069f-6\n",
       " -4.24185f-5  -2.52373f-5  -1.35333f-5  …  -2.67818f-5   1.38686f-5\n",
       " -3.38939f-5   5.39471f-5   7.45425f-6     -6.52051f-5  -2.82521f-6\n",
       " -2.18021f-5   3.84716f-5   2.49129f-5     -6.55062f-5  -5.00323f-7\n",
       " -3.82629f-5   1.61212f-5   2.39591f-6     -1.24829f-5   1.35137f-6\n",
       " -5.05495f-5  -1.33692f-5  -8.82053f-6     -2.40273f-5  -6.40117f-6\n",
       " -3.95111f-5   1.729f-5    -2.08635f-5  …  -8.31179f-5  -1.03269f-5\n",
       " -4.51584f-5   1.73904f-5  -9.46191f-6     -6.54955f-5  -1.16056f-5\n",
       " -3.824f-5     4.39292f-6  -1.45036f-5     -5.40244f-5   1.4898f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       " -3.33194f-5  -2.61955f-5  -6.50996f-6  …   4.23941f-5  -2.50589f-5\n",
       " -3.30358f-5  -2.00184f-5   6.84204f-6      3.12717f-5   9.13305f-6\n",
       " -3.01067f-5  -6.75123f-6  -1.52107f-5      7.49884f-5  -2.1307f-5\n",
       " -1.25077f-5   1.23666f-5  -1.32203f-5      4.95263f-5  -1.44834f-5\n",
       " -3.31196f-5   1.8111f-5    1.68231f-5     -5.05192f-6  -2.42154f-5\n",
       " -3.29181f-5   3.705f-5     2.30836f-5  …  -2.99916f-5  -2.94401f-6\n",
       " -1.3931f-5    1.65682f-5   1.09311f-5     -2.98518f-5  -1.67668f-5\n",
       "  1.41355f-6  -1.75952f-5   2.10338f-5     -2.93998f-5  -1.37844f-5\n",
       " -2.13368f-6   3.05882f-6   5.33108f-6     -3.68394f-6   5.13923f-6\n",
       " -2.10732f-5  -2.22206f-5  -6.24453f-7     -1.09519f-5  -1.02535f-5\n",
       " -2.409f-5     2.24859f-5   4.02295f-5  …  -4.5221f-5    3.5937f-5\n",
       " -3.69512f-6   2.01952f-5   2.7323f-5      -1.48704f-5   1.9243f-5\n",
       "\n",
       "[:, :, 3, 2] =\n",
       " -1.74592f-5  -1.74997f-5  -5.48386f-5  …  -5.44331f-5  -3.44095f-6\n",
       " -1.83681f-5  -4.44512f-5   8.4679f-6      -8.93632f-6  -2.02614f-5\n",
       " -3.12231f-5  -5.07142f-5  -4.06698f-5      7.57807f-6   2.57886f-6\n",
       " -5.193f-5    -3.53402f-5  -5.60197f-5     -3.6503f-5    1.74299f-5\n",
       " -3.89422f-5  -3.12353f-5  -3.00803f-5     -7.22072f-5  -2.20408f-6\n",
       " -3.5434f-5   -2.18438f-5  -1.86923f-5  …  -6.13122f-5   8.3819f-6\n",
       " -4.03734f-5  -5.4682f-5   -4.6048f-5      -3.61934f-5   2.83139f-5\n",
       " -1.2718f-5   -8.38273f-6  -5.85619f-5     -7.62185f-5  -9.23204f-7\n",
       " -1.51614f-5  -6.73181f-8  -3.63488f-5     -7.38372f-5   2.9517f-5\n",
       " -2.84107f-6   3.11206f-6  -3.10412f-5     -4.92477f-5   1.47454f-5\n",
       " -1.48402f-5  -1.41234f-5  -1.64828f-5  …  -5.06296f-5   2.45042f-5\n",
       " -2.71351f-6  -1.48461f-5  -4.34042f-5     -6.62382f-5   3.16573f-5\n",
       " -8.52118f-6  -1.49445f-5  -3.39552f-5     -5.39094f-5  -6.10256f-6\n",
       "  ⋮                                     ⋱   ⋮           \n",
       " -5.70947f-6  -8.23576f-6  -2.4368f-5   …  -5.92869f-5   2.97601f-6\n",
       " -7.42581f-6  -5.52193f-6  -2.21327f-5     -2.283f-5    -2.8122f-5\n",
       " -1.57939f-5  -8.74809f-6  -3.63412f-5     -8.86392f-5   2.15414f-5\n",
       " -1.83793f-5   5.46424f-6  -2.0727f-5      -5.79139f-5  -6.21379f-6\n",
       " -3.21034f-5  -2.89043f-5  -4.30951f-5     -4.99929f-5   6.21828f-6\n",
       " -3.48545f-5  -2.01289f-5  -1.14307f-5  …  -6.38608f-5   1.66537f-6\n",
       " -1.71799f-5  -1.99349f-5  -2.78432f-5     -5.34255f-5   1.73556f-5\n",
       " -2.6964f-5   -4.96389f-5  -1.23764f-5     -5.1133f-5    9.90788f-6\n",
       " -2.28595f-5  -5.90009f-5  -3.3344f-5      -7.45044f-5   3.27374f-5\n",
       " -4.42449f-5  -2.05449f-5  -6.06962f-5     -2.1034f-5    3.60783f-5\n",
       " -3.15115f-5  -4.58785f-5  -6.79208f-6  …  -3.09209f-5  -1.05342f-5\n",
       " -1.26809f-5  -1.68638f-6   1.74821f-5     -7.3265f-6    3.17256f-5\n",
       "\n",
       "[:, :, 1, 3] =\n",
       "  1.673f-5     3.58228f-5   2.27368f-5  …   2.35877f-5  -7.94414f-6\n",
       "  8.29761f-7   2.9443f-6   -1.58849f-5      5.91615f-6  -1.46762f-5\n",
       " -3.78398f-6   1.61924f-5  -2.2282f-5      -2.48632f-5  -1.42742f-5\n",
       " -1.08658f-5   2.22341f-5  -1.15163f-6      3.13923f-6  -2.60388f-5\n",
       "  2.12892f-7   2.15456f-5  -8.04763f-6     -1.02918f-5  -9.85139f-7\n",
       " -3.33927f-6   2.12769f-5   1.15293f-5  …  -2.68574f-5  -3.68058f-5\n",
       " -3.58241f-6   6.44395f-6   1.03993f-5      1.70197f-5  -4.17862f-5\n",
       " -2.39085f-6   1.43534f-5   2.95042f-5      8.001f-6    -2.61732f-5\n",
       " -1.00189f-5   6.33494f-6   3.15009f-5     -1.75087f-5  -3.9304f-5\n",
       " -1.00208f-5   6.32218f-6   3.14733f-5     -1.13633f-5  -1.9755f-6\n",
       " -1.00224f-5   6.32668f-6   3.15212f-5  …  -1.8326f-5   -2.61517f-5\n",
       " -1.00284f-5   6.32401f-6   3.14498f-5     -1.83964f-5  -4.90769f-5\n",
       " -1.3509f-5    7.05112f-6   2.77964f-5     -1.65799f-5  -6.07551f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       " -1.00197f-5   6.33469f-6   3.15067f-5  …  -8.38426f-5   7.09987f-6\n",
       " -1.00207f-5   6.32579f-6   3.14878f-5     -7.45988f-5  -1.21613f-5\n",
       " -1.00221f-5   6.33136f-6   3.15247f-5     -1.26585f-5  -7.34552f-6\n",
       " -1.00192f-5   6.31654f-6   3.14918f-5     -3.12922f-5  -3.60399f-5\n",
       " -1.00168f-5   6.33111f-6   3.15f-5        -1.23178f-5  -3.12944f-5\n",
       " -1.00225f-5   6.33402f-6   3.02633f-5  …   1.85365f-5  -2.21121f-5\n",
       " -1.00216f-5   6.34075f-6   3.30568f-5      1.35102f-5  -1.04262f-6\n",
       " -1.00212f-5   6.3371f-6    3.39381f-5      3.1797f-5   -3.21175f-5\n",
       " -1.04519f-5   6.75512f-6   2.57058f-5     -6.02486f-6  -1.48994f-5\n",
       " -1.53399f-5  -1.67983f-6   2.51841f-5     -1.84045f-5  -7.95714f-6\n",
       " -3.05509f-5  -1.64253f-5  -4.86718f-6  …  -2.21055f-5   2.05303f-5\n",
       " -1.94801f-5  -1.09938f-5  -1.66831f-6     -1.37712f-6   2.03827f-5\n",
       "\n",
       "[:, :, 2, 3] =\n",
       " -4.02194f-5  -2.66397f-5  -2.09566f-5  …   6.05227f-6   1.48781f-6\n",
       " -3.32982f-5  -9.84823f-6   9.32193f-6      5.07623f-5   1.8126f-5\n",
       " -2.06137f-5   9.61018f-6  -6.80612f-6     -4.34933f-7   1.94262f-5\n",
       " -2.42156f-5   2.12035f-6   1.92868f-5     -4.68448f-5  -6.94904f-6\n",
       " -3.56341f-5  -8.19877f-6  -1.79397f-5     -3.29622f-5   6.81552f-6\n",
       " -3.99447f-5   1.62882f-5   4.9866f-6   …  -3.67735f-5  -2.68107f-5\n",
       " -5.03973f-5   3.58614f-6   2.42254f-5     -3.17634f-5   1.0486f-5\n",
       " -4.89504f-5  -5.94371f-7   1.37025f-5     -1.3184f-6   -9.45665f-6\n",
       " -4.39049f-5   4.86961f-6   1.28626f-5     -2.32635f-6  -9.71466f-6\n",
       " -4.39009f-5   4.8853f-6    1.28599f-5     -3.35148f-5   1.25536f-6\n",
       " -4.38926f-5   4.91183f-6   1.28699f-5  …  -4.70152f-5  -4.01541f-5\n",
       " -4.38982f-5   4.84069f-6   1.30608f-5     -3.42487f-5  -5.69816f-5\n",
       " -4.17684f-5   5.0087f-6    1.10878f-5     -5.56672f-5  -3.0295f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       " -4.38971f-5   4.9044f-6    1.28511f-5  …  -2.37081f-5  -1.44734f-5\n",
       " -4.38944f-5   4.91216f-6   1.28679f-5     -2.64996f-5  -3.13683f-5\n",
       " -4.3888f-5    4.90556f-6   1.29031f-5     -1.5943f-5    6.30613f-6\n",
       " -4.3884f-5    4.90009f-6   1.28769f-5     -3.79362f-6   9.1648f-6\n",
       " -4.38811f-5   4.88037f-6   1.28562f-5     -6.45328f-6  -1.56383f-5\n",
       " -4.38777f-5   4.87784f-6   1.09659f-5  …  -2.7132f-5   -1.68552f-5\n",
       " -4.38829f-5   4.88331f-6   1.22844f-5     -5.00289f-5  -1.31267f-5\n",
       " -4.38805f-5   4.90477f-6   1.51183f-5     -1.00468f-5  -3.35841f-5\n",
       " -4.12651f-5   6.26538f-6   1.17097f-5     -3.31804f-5  -2.69843f-5\n",
       " -3.31685f-5   1.2379f-5    2.40441f-5     -7.20223f-5  -1.15213f-5\n",
       " -2.78691f-5   1.47127f-5   9.2549f-6   …  -2.23174f-5  -2.52449f-5\n",
       "  2.65396f-5   1.9566f-5    1.23495f-5      2.94895f-5   3.35168f-6\n",
       "\n",
       "[:, :, 3, 3] =\n",
       " 4.2657f-5   3.76445f-5  3.48088f-5  4.16299f-5  …   2.24227f-5  -2.53212f-6\n",
       " 3.70308f-5  1.12334f-5  4.10047f-5  2.55191f-5      2.13241f-5   1.92683f-5\n",
       " 3.06632f-5  4.20065f-5  2.55308f-5  5.07773f-5      4.84668f-5   1.93949f-5\n",
       " 3.34475f-5  4.08824f-5  3.21244f-5  3.70629f-5      5.35671f-5   5.93238f-5\n",
       " 3.96701f-5  4.43425f-5  2.47967f-5  7.57918f-5     -2.84415f-6   3.33555f-6\n",
       " 3.75065f-5  4.55134f-5  2.3838f-5   5.57132f-5  …   5.44182f-5   5.9811f-5\n",
       " 4.76374f-5  4.24026f-5  6.50115f-5  7.04398f-5     -1.03372f-5   6.82667f-7\n",
       " 4.62276f-5  3.04685f-5  6.15417f-5  6.42952f-5      5.91394f-5   6.42733f-6\n",
       " 4.77115f-5  3.60125f-5  5.61337f-5  5.53433f-5      1.94664f-5  -9.00418f-6\n",
       " 4.77108f-5  3.60209f-5  5.61346f-5  4.62904f-5      1.38357f-5  -1.10861f-5\n",
       " 4.77071f-5  3.60083f-5  5.61364f-5  6.19448f-5  …   4.37119f-5   6.02287f-6\n",
       " 4.77202f-5  3.60737f-5  5.5971f-5   6.40201f-5      4.52983f-5   8.58567f-6\n",
       " 4.32903f-5  3.36475f-5  6.25609f-5  5.30161f-5      3.21094f-5   3.11472f-5\n",
       " ⋮                                               ⋱   ⋮           \n",
       " 4.77122f-5  3.60151f-5  5.61367f-5  4.79026f-5  …   4.01952f-5   1.07653f-5\n",
       " 4.77119f-5  3.60234f-5  5.61324f-5  5.07737f-5      2.85871f-5   5.18471f-6\n",
       " 4.77085f-5  3.59914f-5  5.6147f-5   5.82631f-5      3.98007f-5  -1.09274f-5\n",
       " 4.7712f-5   3.60166f-5  5.60761f-5  6.97482f-5      7.31916f-5   1.46334f-5\n",
       " 4.77061f-5  3.60107f-5  5.61527f-5  5.09075f-5      4.04227f-5   2.32633f-5\n",
       " 4.77069f-5  3.60371f-5  5.7262f-5   4.27788f-5  …   2.33336f-5   5.32742f-6\n",
       " 4.77075f-5  3.60631f-5  5.66137f-5  4.57829f-5      3.41001f-5   2.79365f-5\n",
       " 4.77096f-5  3.6038f-5   5.3215f-5   4.97969f-5      1.61323f-5   1.57816f-5\n",
       " 4.62957f-5  3.40246f-5  5.79603f-5  5.17855f-5      1.30125f-5   7.61319f-6\n",
       " 4.2304f-5   2.38028f-5  5.79542f-5  4.15655f-5      2.76623f-5   3.31381f-5\n",
       " 2.24679f-5  2.31046f-5  5.80093f-5  2.81037f-5  …   3.81339f-5   5.43936f-5\n",
       " 1.37904f-5  5.93686f-6  2.47666f-5  2.42595f-5      1.62254f-5   1.97552f-5\n",
       "\n",
       ";;;; … \n",
       "\n",
       "[:, :, 1, 14] =\n",
       "  8.36695f-6   1.36324f-6   8.83994f-6  …  3.94241f-5   7.13856f-6\n",
       " -6.00785f-6   3.1106f-5    2.49954f-5     3.26521f-5  -7.29172f-6\n",
       " -4.74888f-6   5.86787f-5   5.84997f-5     4.37821f-5   3.54432f-6\n",
       "  2.0778f-5    1.17082f-5   6.94903f-5     4.45635f-5  -7.19697f-6\n",
       "  6.62519f-6  -9.21726f-6   5.99114f-5     5.23374f-5   3.82559f-6\n",
       " -6.89875f-6   1.21826f-5   6.70678f-5  …  3.47038f-5   2.07599f-6\n",
       " -2.8245f-5    2.801f-5     6.30407f-5     3.43908f-5  -9.26206f-7\n",
       " -5.38572f-6   1.37488f-5   5.1908f-5      4.06024f-5  -3.03219f-7\n",
       " -1.59864f-5   2.26574f-5   2.08824f-5     3.88608f-5   1.59127f-6\n",
       "  7.9169f-6    3.69397f-5  -2.95786f-5     5.58652f-5   1.04994f-5\n",
       "  5.07182f-7   3.59088f-5   1.65327f-5  …  5.10775f-5  -4.19451f-6\n",
       "  1.35471f-5   4.59381f-5   1.53729f-5     6.84813f-5  -2.17383f-6\n",
       "  6.91318f-6   6.87636f-5   3.60215f-5     4.69064f-5  -5.15218f-6\n",
       "  ⋮                                     ⋱  ⋮           \n",
       "  2.69582f-5  -4.06514f-6  -1.04876f-5  …  4.29473f-5  -4.90474f-6\n",
       " -5.29594f-6  -2.80668f-5   3.01655f-5     4.37808f-5  -5.33701f-6\n",
       " -3.6812f-6    5.34545f-6   6.25981f-5     4.0998f-5   -4.99956f-6\n",
       "  8.5997f-7    2.83645f-5   2.63785f-5     4.63888f-5  -9.65316f-7\n",
       "  1.84098f-5   4.7512f-5    3.88375f-5     4.6452f-5    7.80971f-7\n",
       " -2.13332f-6   3.24326f-5  -4.65792f-6  …  4.10994f-5   3.89664f-6\n",
       "  1.02883f-5   4.81269f-5   8.03318f-5     4.1496f-5   -1.95343f-7\n",
       "  2.16518f-5   9.6507f-7    2.55848f-5     2.18091f-5   7.22339f-6\n",
       " -9.00109f-6  -2.45884f-5   3.89414f-5     4.20798f-5  -1.69807f-5\n",
       "  2.62184f-5  -2.82837f-5   5.21915f-6     3.08241f-5  -1.10849f-5\n",
       "  2.308f-5    -2.15076f-5  -4.92079f-6  …  1.89037f-5  -1.5549f-5\n",
       "  3.73436f-5   1.39539f-5   2.43462f-5     3.06605f-5  -9.17516f-6\n",
       "\n",
       "[:, :, 2, 14] =\n",
       "  6.14696f-5   3.92912f-5   6.18235f-5  …   3.71148f-5   3.98862f-5\n",
       "  4.17041f-5   1.73231f-5   4.11691f-5      9.27614f-6   7.98058f-6\n",
       "  3.58811f-5  -7.78011f-6   3.53384f-5      1.68684f-5   1.29482f-5\n",
       "  1.76203f-5   1.76686f-6   4.50222f-5      1.60889f-5   1.69524f-5\n",
       "  3.55607f-5  -1.28924f-5   6.9251f-5       1.78434f-5   3.10276f-6\n",
       "  2.10002f-5   1.56947f-5   7.38747f-5  …   1.51723f-5   6.87312f-6\n",
       "  2.56321f-5   3.2668f-5    4.7987f-5       1.40198f-5   8.99581f-6\n",
       "  2.68984f-5   3.33226f-5   5.78065f-5      1.76097f-5   1.14649f-5\n",
       "  6.06401f-5   2.48529f-5   7.2172f-5       1.64586f-5  -1.07242f-5\n",
       "  3.08971f-5   4.94119f-5   3.83718f-5      6.60523f-6   5.44412f-6\n",
       "  4.56468f-5   3.75019f-5   2.74859f-5  …   1.59042f-5   1.36046f-5\n",
       "  3.98255f-5   4.13133f-5   3.67479f-5      5.45686f-6   1.38759f-6\n",
       "  5.11396f-5   2.5499f-5    3.33749f-5      3.55107f-5   8.97933f-6\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  6.59367f-5   4.8852f-5    4.4613f-5   …   1.52249f-5   3.84152f-6\n",
       "  8.79428f-5   6.96223f-5   6.79073f-5      1.78797f-5   3.89644f-6\n",
       "  5.1822f-5    5.81359f-5   4.57239f-5      1.58425f-5   4.42202f-6\n",
       "  4.10855f-5   5.07378f-5  -3.03899f-6      9.25023f-6   2.60705f-6\n",
       "  4.91068f-5   4.52457f-6   1.00846f-5      8.9902f-6    5.99991f-6\n",
       "  7.28389f-5   5.57403f-5   7.8032f-6   …   1.64031f-5   7.75639f-6\n",
       "  9.49864f-5   4.74503f-5   3.93831f-7      2.3536f-5   -2.23786f-6\n",
       "  9.44011f-5   9.2077f-6    2.49199f-5      1.94404f-5   2.34876f-5\n",
       "  4.60913f-5   4.70449f-5   1.55346f-5      2.23541f-5  -2.23429f-5\n",
       "  2.54435f-5  -1.01209f-5  -1.8816f-5       8.41175f-6  -2.37532f-5\n",
       "  4.00628f-5   1.69742f-5   3.21267f-6  …   5.89182f-8  -2.17452f-5\n",
       " -1.78715f-5  -1.82958f-5  -2.33947f-5     -1.63761f-5  -2.07084f-5\n",
       "\n",
       "[:, :, 3, 14] =\n",
       "  1.03694f-5  -9.69724f-6  -9.56658f-6  …  -3.26667f-5   2.64031f-6\n",
       "  1.01944f-5   1.70231f-5   3.88997f-6     -2.58986f-5   1.18846f-5\n",
       "  3.89094f-5   5.01433f-5  -9.20578f-6     -3.45481f-5  -3.66577f-6\n",
       "  4.86085f-5   1.68279f-5  -4.10591f-5     -4.68553f-7   5.33721f-6\n",
       "  7.0252f-5    5.03547f-6  -1.74745f-5     -1.45141f-5  -9.31434f-6\n",
       "  5.26023f-5   1.74778f-6  -2.65632f-5  …  -2.27393f-5  -1.2436f-5\n",
       "  3.5099f-5   -7.17588f-7  -1.98247f-5     -3.77672f-6  -4.59632f-6\n",
       "  3.31982f-5  -3.33649f-5  -3.33365f-5     -9.69058f-6  -8.3738f-6\n",
       "  4.8962f-5   -2.90659f-6  -7.5801f-7      -9.59028f-6  -1.0384f-5\n",
       "  2.92419f-5   9.51058f-6   2.64957f-6     -1.01352f-5  -5.64233f-6\n",
       "  6.43896f-6  -2.15831f-5  -2.88878f-6  …  -1.8279f-7   -7.82066f-7\n",
       "  1.2283f-5   -3.7253f-5   -3.95326f-7     -1.68149f-5  -1.09814f-5\n",
       "  1.82994f-5  -1.88592f-5   1.73594f-5     -3.54864f-5  -4.97204f-6\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  2.05848f-5  -3.35076f-5  -3.2614f-5   …  -1.5033f-5   -4.05054f-6\n",
       "  2.33634f-5  -1.43335f-5  -8.4114f-6      -1.69662f-5  -4.59666f-6\n",
       " -6.20464f-6  -1.61929f-5  -3.6198f-6      -1.57719f-5  -2.83211f-6\n",
       " -2.02935f-5  -1.27634f-5  -5.68703f-6     -1.22614f-5  -1.08681f-6\n",
       " -1.03804f-5  -2.57213f-5   6.35156f-7     -1.12802f-5  -6.28061f-6\n",
       "  7.63991f-6  -1.28986f-5   3.04851f-5  …  -1.30443f-5  -8.30688f-6\n",
       "  2.46267f-5  -3.82005f-5  -3.32914f-5     -1.24005f-5  -6.02625f-6\n",
       "  3.28527f-5  -1.33104f-5   1.5491f-6      -3.1198f-5   -4.43656f-6\n",
       "  1.90003f-5  -6.3121f-6   -1.36689f-5      1.26932f-5  -2.68575f-7\n",
       " -8.6526f-6   -8.60718f-6  -2.58791f-5     -1.55694f-6  -5.87538f-6\n",
       "  6.75501f-6  -2.07352f-5  -1.53184f-5  …  -2.33396f-6   5.77097f-6\n",
       "  1.5766f-5    5.89461f-6   2.15791f-6      6.84693f-6  -2.81101f-6\n",
       "\n",
       "[:, :, 1, 15] =\n",
       "  1.53853f-5   3.28241f-5  3.95255f-5   …  4.57831f-5    4.52817f-5\n",
       " -1.00592f-5   1.83706f-5  5.52844f-5      0.000102392   3.34934f-5\n",
       "  1.36648f-5   3.58663f-5  8.64317f-5      7.97782f-5   -2.88927f-6\n",
       "  3.64142f-5   4.98713f-5  6.30854f-5      9.24861f-5   -1.21155f-5\n",
       "  2.6111f-5    5.1378f-5   7.02151f-5      7.48864f-5   -1.67451f-5\n",
       "  1.30831f-5   6.53791f-5  6.49135f-5   …  7.32739f-5   -1.27193f-5\n",
       "  1.29841f-5   5.51833f-5  5.93901f-5      6.65618f-5   -1.17255f-5\n",
       "  9.0783f-6    4.13741f-5  9.99894f-5      6.41777f-5   -2.44047f-5\n",
       "  3.01459f-5   6.76301f-5  0.000116178     6.68452f-5   -8.93244f-6\n",
       "  2.44256f-5   4.06475f-5  9.42645f-5      6.43437f-5   -1.75583f-5\n",
       "  1.79847f-5   4.17586f-5  8.05503f-5   …  6.64905f-5   -8.39665f-6\n",
       "  2.41832f-5   5.71723f-5  9.7032f-5       5.43365f-5   -9.81356f-6\n",
       "  1.81422f-5   7.75264f-5  8.17544f-5      5.25645f-5   -1.0643f-5\n",
       "  ⋮                                     ⋱  ⋮            \n",
       "  2.47778f-5   5.65155f-5  7.32983f-5   …  5.70189f-5   -1.82428f-6\n",
       "  2.12216f-5   6.661f-5    7.98058f-5      7.1398f-5    -1.62685f-5\n",
       "  8.67271f-6   5.06911f-5  7.70541f-5      5.67742f-5   -1.29665f-5\n",
       "  2.43277f-5   6.30119f-5  7.65923f-5      8.42681f-5   -2.32053f-5\n",
       "  3.11249f-5   5.79489f-5  7.77278f-5      5.74891f-5   -1.41755f-5\n",
       "  2.49112f-5   5.17083f-5  7.03254f-5   …  6.94005f-5   -5.40429f-6\n",
       "  1.59893f-5   7.02242f-5  6.49211f-5      9.56479f-5   -1.58741f-5\n",
       "  2.02681f-5   4.57809f-5  7.7112f-5       0.000105307   1.10435f-5\n",
       "  1.84685f-7   9.59887f-6  3.26794f-5      7.8763f-5     1.53191f-5\n",
       " -1.14647f-5  -1.21473f-5  7.37786f-6      4.08587f-5   -8.39937f-6\n",
       "  7.81165f-6   1.7998f-7   1.74344f-5   …  4.7766f-5    -1.53713f-5\n",
       "  4.20441f-5   3.24673f-5  4.26f-5         2.96728f-5   -6.17398f-6\n",
       "\n",
       "[:, :, 2, 15] =\n",
       "  5.87082f-5   4.44131f-5   3.68966f-5  …   1.15009f-5   1.84214f-5\n",
       "  7.71467f-5   5.86319f-5   4.12135f-5      4.91625f-6   2.81683f-7\n",
       "  6.01084f-5   1.19297f-5   7.97949f-6      1.32937f-5   1.82949f-5\n",
       "  2.40938f-5   3.15374f-5   2.72792f-5      2.10553f-5   2.25345f-5\n",
       "  3.82091f-5   3.32584f-5   9.51494f-6      2.47279f-5   2.57229f-5\n",
       "  5.31673f-5   2.08825f-5   2.00516f-5  …   2.65366f-5   2.13427f-5\n",
       "  4.89296f-5   3.71605f-5   3.27007f-5      3.09797f-5   2.69491f-5\n",
       "  8.47241f-5   2.7952f-5    1.11023f-5      4.24241f-5   2.2188f-5\n",
       "  2.89033f-5   3.03256f-5   2.60894f-5      4.61345f-5   2.05363f-5\n",
       "  3.47805f-5   3.37028f-5   3.23773f-5      2.04638f-5   1.34638f-5\n",
       "  4.85439f-5   3.67939f-5   2.44482f-5  …   2.60188f-5   8.92841f-6\n",
       "  4.13319f-5   3.77463f-5   1.86152f-5      2.77614f-5   1.35819f-5\n",
       "  4.9404f-5    1.66981f-5   2.54397f-5      2.50493f-5   1.13354f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  4.88494f-5   2.38537f-5   2.47131f-5  …   1.27928f-5   2.073f-5\n",
       "  4.4112f-5    2.2875f-5    2.00312f-5      3.82673f-5   2.05491f-5\n",
       "  4.88786f-5   2.15426f-5   2.79879f-5      2.4727f-5    2.15831f-5\n",
       "  4.39603f-5   1.26462f-5   5.46334f-6      1.72602f-5   9.93699f-6\n",
       "  4.08077f-5   1.35242f-5   7.23864f-6      2.25865f-5   1.40242f-5\n",
       "  3.71464f-5   1.77354f-5   1.25543f-5  …   4.47504f-6   1.58259f-5\n",
       "  4.0611f-5    2.73977f-5   3.38501f-6      2.81481f-5  -2.61267f-8\n",
       "  3.16379f-5   3.48261f-5   2.41092f-5      7.38465f-7  -5.32513f-6\n",
       "  4.09393f-5   2.75084f-5   2.00843f-5      2.60288f-5  -2.47657f-6\n",
       "  7.61222f-5   6.53093f-5   5.48163f-5      4.56434f-5  -5.95635f-7\n",
       "  4.59648f-5   9.38025f-6  -2.6246f-6   …  -1.34728f-5   9.84029f-7\n",
       " -1.86597f-5  -2.61568f-5  -3.23923f-5     -1.59793f-5  -1.82647f-5\n",
       "\n",
       "[:, :, 3, 15] =\n",
       "  3.53424f-6  -2.016f-5    -1.96142f-5  …  -8.78243f-6   7.02963f-7\n",
       "  3.22527f-5  -4.91381f-6  -4.17957f-5     -4.27149f-5  -2.1788f-6\n",
       "  2.20798f-5  -1.54853f-5  -1.00378f-5     -7.76493f-6   1.44991f-5\n",
       "  5.23299f-6  -1.80231f-6  -2.29229f-5     -1.51815f-5   9.04877f-7\n",
       " -6.59385f-6   5.19335f-6  -1.5246f-5      -1.23513f-5  -4.01298f-7\n",
       " -7.47702f-6  -1.30668f-5  -2.53218f-5  …  -5.74397f-6   5.42382f-6\n",
       " -7.65197f-6  -2.20061f-5  -3.1372f-5      -1.14819f-5   9.98624f-7\n",
       "  2.61195f-5  -1.95454f-5  -2.84736f-5     -1.02154f-5   4.04751f-7\n",
       "  1.24927f-5  -2.65489f-5  -3.67365f-5     -1.02246f-5  -8.55173f-7\n",
       "  1.12861f-6  -1.70295f-6   4.3245f-6      -1.35776f-5   1.54029f-6\n",
       " -2.64307f-6  -1.39943f-5  -2.40423f-5  …  -2.16059f-5  -9.67822f-6\n",
       "  1.38903f-5  -1.99065f-5  -4.90428f-5     -1.71709f-5  -7.54717f-6\n",
       " -6.51749f-6  -1.49441f-5  -3.97293f-5     -1.31024f-5  -3.9346f-6\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  9.7468f-6   -2.95806f-5  -1.212f-5    …  -1.92645f-5  -5.68982f-6\n",
       "  1.02384f-5  -2.84852f-5  -2.32715f-5     -1.28054f-5   2.6893f-6\n",
       "  9.95596f-6  -1.00969f-5  -3.43718f-5      1.20554f-6  -1.58316f-6\n",
       "  3.41995f-6  -3.19735f-5  -2.27478f-5     -3.1069f-5   -2.8943f-6\n",
       "  3.92846f-6  -2.49225f-5  -1.54226f-5     -1.80133f-5  -7.79764f-6\n",
       "  1.19965f-6  -5.75793f-6  -4.7621f-6   …  -6.96299f-6  -9.05585f-7\n",
       " -1.38216f-5  -1.13163f-5  -1.79128f-5     -2.42995f-6   1.20803f-5\n",
       " -1.16502f-5  -2.31787f-5  -2.04518f-5     -8.0222f-7    1.42217f-5\n",
       " -5.60187f-6  -5.86389f-5  -3.08374f-5     -3.23239f-5  -3.50477f-6\n",
       "  1.93547f-5  -1.32945f-5  -1.06811f-5     -1.74414f-5   7.12161f-6\n",
       "  1.40409f-6  -1.771f-5    -1.49669f-5  …  -1.37198f-5   1.04435f-5\n",
       "  1.36219f-5   5.50054f-6   5.66323f-6      5.24876f-6   5.34814f-6\n",
       "\n",
       "[:, :, 1, 16] =\n",
       "  2.38772f-5   6.62933f-5  …  3.4337f-5   3.6395f-5    3.81958f-5\n",
       "  1.98284f-5   5.7033f-5      4.57993f-5  4.09419f-5   8.21513f-6\n",
       "  1.12085f-5  -2.01045f-5     4.93528f-5  3.76306f-5   3.89286f-5\n",
       "  4.07306f-5   1.64131f-5     6.4724f-5   3.47729f-5   9.48856f-6\n",
       "  5.87857f-5  -1.71665f-6     5.97948f-5  3.30068f-5   2.03239f-5\n",
       "  2.14452f-5   3.39876f-5  …  6.71884f-5  2.4078f-5    1.35896f-5\n",
       " -3.70159f-6   2.03399f-5     4.36129f-5  3.07375f-5   1.09924f-5\n",
       "  9.71321f-6   1.40136f-6     5.92071f-5  4.32727f-5   1.72868f-5\n",
       "  4.03539f-5  -3.90923f-6     7.00451f-5  5.75141f-5   1.45453f-5\n",
       "  6.39859f-5   9.54789f-6     7.38585f-5  3.78607f-5   2.55241f-5\n",
       "  6.01798f-5   2.46034f-5  …  5.29168f-5  3.93003f-5   8.61227f-6\n",
       "  7.52172f-5   2.18807f-5     3.60262f-5  3.99366f-5   8.56829f-6\n",
       "  8.65543f-5   5.19311f-5     5.1856f-5   4.02011f-5   9.5342f-6\n",
       "  ⋮                        ⋱              ⋮           \n",
       "  5.24372f-5   3.77529f-5  …  5.5913f-5   5.36526f-5   6.93507f-6\n",
       "  3.88066f-5   2.52782f-5     6.29722f-5  6.07427f-5   1.88887f-5\n",
       "  3.38911f-5   6.34704f-6     6.0556f-5   5.06116f-5   6.68305f-6\n",
       "  3.17501f-5   3.53889f-5     5.74215f-5  4.84697f-5   1.54382f-5\n",
       "  7.58207f-6   3.83512f-5     5.29464f-5  4.06687f-5   8.48703f-6\n",
       "  2.16938f-5   2.46154f-5  …  4.14636f-5  4.63824f-5   3.76778f-6\n",
       "  2.38047f-5  -3.43294f-5     3.73223f-5  2.67046f-5  -5.32898f-6\n",
       "  1.40574f-5  -7.10312f-5     3.50551f-5  3.08792f-5  -3.2925f-6\n",
       "  1.27928f-6  -5.9224f-6      5.21956f-5  6.48119f-5  -1.27463f-5\n",
       "  7.09826f-5   0.00011108     6.1788f-5   7.29361f-5   3.09022f-5\n",
       "  6.38339f-5   2.76327f-6  …  2.60546f-5  2.20188f-5   1.12537f-6\n",
       "  4.06952f-5   2.18427f-5     2.22114f-5  2.40222f-5  -2.01434f-5\n",
       "\n",
       "[:, :, 2, 16] =\n",
       "  3.92981f-5  1.82316f-5   -4.31684f-6  …   8.74656f-6   8.2537f-6\n",
       "  6.28313f-5  1.04235f-5    5.28566f-5     -5.81144f-6  -2.06972f-5\n",
       "  0.0001066   9.36257f-5    1.19739f-6      2.13507f-5   1.37851f-5\n",
       "  7.31804f-6  9.80584f-5    3.66751f-5      2.09932f-5   3.8418f-7\n",
       " -1.01318f-5  4.44865f-5    8.28947f-5      2.66445f-5  -1.36488f-5\n",
       "  6.48792f-6  3.53879f-5    1.19248f-5  …   3.47471f-5   5.0983f-6\n",
       "  2.08354f-5  1.99226f-5    1.26428f-5      1.91626f-5  -1.5952f-5\n",
       "  3.83787f-5  3.20898f-5   -1.89844f-6      1.52913f-5  -2.84058f-5\n",
       "  1.18271f-5  2.72945f-5    1.35531f-6      7.50804f-7   7.5868f-7\n",
       "  3.86945f-5  4.67956f-5    3.41174f-5      4.74536f-6   3.39375f-5\n",
       "  4.32295f-5  3.43931f-5    2.37934f-5  …   4.88072f-5   9.74532f-6\n",
       "  2.16308f-5  3.18167f-5   -1.21001f-5      1.25869f-5  -5.54601f-6\n",
       "  2.74292f-6  1.45954f-5   -2.11509f-5      2.78085f-5   1.78829f-5\n",
       "  ⋮                                     ⋱   ⋮           \n",
       "  1.2881f-5   4.1759f-6    -3.28302f-6  …   3.36609f-5   1.7385f-5\n",
       "  1.51421f-5  2.5127f-5     1.50683f-5      3.67197f-5   7.78242f-6\n",
       "  9.63272f-6  3.38345f-5    2.17047f-5      2.82102f-5   2.80057f-5\n",
       " -2.85269f-6  4.79714f-5    7.58391f-6      4.70548f-5   2.13284f-5\n",
       "  4.95448f-6  4.45233f-5    4.91791f-6      3.50697f-5   2.00904f-5\n",
       "  1.40975f-5  3.56744f-5    3.2748f-6   …   3.78868f-5   2.07295f-5\n",
       "  1.03167f-5  7.3834f-5     3.92293f-5      3.43122f-5   2.40567f-5\n",
       "  1.46179f-5  0.000155297   3.94401f-5      1.38323f-5   2.85933f-5\n",
       "  3.01821f-5  7.62965f-5    1.55878f-5      1.53503f-5   2.07198f-5\n",
       "  1.72636f-5  1.41694f-5   -1.29752f-5     -1.93796f-5   1.54477f-5\n",
       "  5.91252f-5  4.70961f-5    4.76129f-5  …  -8.81015f-7   2.42048f-5\n",
       "  1.92431f-6  1.20104f-5    1.70509f-5      8.6678f-6   -2.46647f-6\n",
       "\n",
       "[:, :, 3, 16] =\n",
       " -7.0159f-5   -6.98921f-5   -1.65556f-5  …  -4.91598f-5  -2.33457f-5\n",
       " -1.66782f-5  -0.000106458  -8.5916f-5       9.55886f-6   1.4798f-5\n",
       "  1.39646f-5  -2.47321f-5   -8.27254f-5     -4.39535f-5  -9.72437f-6\n",
       " -3.63873f-5  -1.05687f-5   -7.85856f-6     -3.30842f-5  -5.88335f-6\n",
       " -8.08267f-5   5.19544f-6    3.05326f-5     -1.63047f-5  -6.55356f-6\n",
       " -5.43093f-5  -5.56328f-5   -2.64155f-5  …  -1.85262f-5  -1.00562f-5\n",
       " -1.48981f-5  -5.48729f-5   -5.01213f-5     -3.66088f-5  -3.4464f-6\n",
       " -2.38938f-6  -2.18895f-5   -2.89432f-5      7.26816f-7  -9.13441f-6\n",
       " -2.07253f-5   1.37189f-6   -5.14033f-5     -3.75156f-5  -1.21909f-5\n",
       " -4.07014f-5  -2.65552f-5   -2.13564f-5     -3.33977f-5  -1.05166f-5\n",
       " -3.44607f-6  -3.34071f-5   -4.79846f-5  …  -1.19624f-5   1.37485f-6\n",
       " -8.8378f-6   -1.01578f-6   -7.00514f-7     -1.76017f-5  -2.76893f-6\n",
       " -1.34965f-6  -1.35477f-5   -2.39633f-5     -5.37276f-5  -2.52451f-5\n",
       "  ⋮                                      ⋱   ⋮           \n",
       " -1.63724f-5  -4.29281f-5   -2.08774f-5  …  -3.73327f-5  -2.28046f-5\n",
       " -2.67263f-5  -6.7241f-5    -3.52749f-5     -3.15964f-5  -2.44878f-5\n",
       " -3.39469f-5  -6.83299f-5   -2.45309f-5     -1.64335f-5  -2.3294f-5\n",
       " -4.1446f-5   -8.18097f-5   -2.37844f-5     -4.88421f-5  -1.27503f-5\n",
       " -2.42243f-5  -4.05041f-5   -2.82006f-5     -1.50699f-5  -2.0807f-5\n",
       " -2.88257f-5  -3.5979f-5    -1.37222f-5  …  -3.94087f-5  -1.88992f-5\n",
       " -3.94919f-5  -8.63095f-5   -5.26079f-5     -3.36738f-5  -1.46212f-5\n",
       " -4.93124f-5  -5.68957f-5   -4.65481f-5     -4.58123f-5  -1.55913f-5\n",
       " -7.43214f-6   8.64323f-7    1.78407f-5     -1.18888f-5   7.60075f-6\n",
       " -6.64617f-5  -1.91f-5      -1.94509f-6     -3.38016f-5   2.34862f-6\n",
       " -3.88408f-5  -6.30549f-5   -2.78266f-5  …  -2.57723f-5   5.48673f-6\n",
       "  1.10546f-5   2.67419f-5    3.56007f-5     -1.43334f-5  -1.41014f-5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(model, test_loader)\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for (x, y) in test_loader\n",
    "        # Get model predictions\n",
    "        # Note argmax of nd-array gives CartesianIndex\n",
    "        # Need to grab the first element of each CartesianIndex to get the true index\n",
    "        logits = model(x)\n",
    "        ŷ = map(i -> i[1], argmax(logits, dims=1))\n",
    "        append!(preds, ŷ)\n",
    "\n",
    "        # Get true labels\n",
    "        append!(targets, y)\n",
    "    end\n",
    "    accuracy = sum(preds .== targets) / length(targets)\n",
    "    return accuracy\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
       "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
       "                   ───────────────────────   ────────────────────────\n",
       " Tot / % measured:      358ms /   0.0%           44.0MiB /   0.0%    \n",
       "\n",
       " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
       " ────────────────────────────────────────────────────────────────────\n",
       "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup timing output\n",
    "const to = TimerOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] chainrules_transform!(tape::Umlaut.Tape{Yota.GradCtx})",
      "    @ Yota ~/.julia/packages/Yota/KJQ6n/src/grad.jl:189",
      "  [2] gradtape!(tape::Umlaut.Tape{Yota.GradCtx}; seed::Int64)",
      "    @ Yota ~/.julia/packages/Yota/KJQ6n/src/grad.jl:271",
      "  [3] gradtape(::Function, ::ResNet20, ::Vararg{Any}; ctx::Yota.GradCtx, seed::Int64)",
      "    @ Yota ~/.julia/packages/Yota/KJQ6n/src/grad.jl:300",
      "  [4] grad(::Function, ::ResNet20, ::Vararg{Any}; seed::Int64)",
      "    @ Yota ~/.julia/packages/Yota/KJQ6n/src/grad.jl:370",
      "  [5] grad(::Function, ::ResNet20, ::Vararg{Any})",
      "    @ Yota ~/.julia/packages/Yota/KJQ6n/src/grad.jl:362",
      "  [6] macro expansion",
      "    @ ./In[63]:14 [inlined]",
      "  [7] macro expansion",
      "    @ ~/.julia/packages/TimerOutputs/4yHI4/src/TimerOutput.jl:237 [inlined]",
      "  [8] macro expansion",
      "    @ ./In[63]:9 [inlined]",
      "  [9] top-level scope",
      "    @ ~/.julia/packages/TimerOutputs/4yHI4/src/TimerOutput.jl:237 [inlined]",
      " [10] top-level scope",
      "    @ ./In[63]:0",
      " [11] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [12] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "last_loss = 0;\n",
    "@timeit to \"total_training_time\" begin\n",
    "    for epoch in 1:10\n",
    "        timing_name = epoch > 1 ? \"average_epoch_training_time\" : \"train_jit\"\n",
    "\n",
    "        # Create lazily evaluated augmented training data\n",
    "        train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));\n",
    "\n",
    "        @timeit to timing_name begin\n",
    "            losses = []\n",
    "            for (x, y) in train_batches\n",
    "                # loss_function does forward pass\n",
    "                # Yota.jl grad function computes model parameter gradients in g[2]\n",
    "                loss, g = grad(loss_function, model, x, y)\n",
    "                \n",
    "                # Optimiser updates parameters\n",
    "                Optimisers.update!(state, model, g[2])\n",
    "                push!(losses, loss)\n",
    "            end\n",
    "            last_loss = mean(losses)\n",
    "            @info(\"epoch (mean(losses))\")\n",
    "        end\n",
    "        # timing_name = epoch > 1 ? \"average_inference_time\" : \"eval_jit\"\n",
    "        # @timeit to timing_name begin\n",
    "        #     acc = evaluate(model, test_loader)\n",
    "        #     @info(\"epoch (acc)\")\n",
    "        # end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
