{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf641c4e-893e-4be9-9c3f-9778c1abd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from timeit import default_timer\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02456673-8331-4436-be6e-9b4769f71910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:01:54.230979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split = ['train', 'test'],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    "    with_info = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd617244-4270-4683-bc72-768bf2e2ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., tf.one_hot(label, depth = 10)\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc6eb9d-50f3-43cc-b0ff-696bce4bb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9efb4cad-166c-40bd-a791-3a763dda009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Model...\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3e915b-51a2-4733-b234-11fb493b7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a20934e-2f46-4e63-a9e3-4926ad9d5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, logs = {}):\n",
    "        self.logs = []\n",
    "        \n",
    "        self.start_list = []\n",
    "        self.end_list = []\n",
    "        self.difference_list = []\n",
    "        \n",
    "        self.start_train_time = 0.0\n",
    "        self.end_train_time = 0.0\n",
    "        \n",
    "        self.start_batch_interference_list = []\n",
    "        self.end_batch_interference_list = []\n",
    "        self.difference_batch_interference_list = []\n",
    "        \n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.start_train_time = time.time()\n",
    "    def on_train_end(self, logs = {}):\n",
    "        self.end_train_time = time.time()\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs = {}):\n",
    "        self.starttime = time.time()\n",
    "        self.start_batch_interference_list.append(self.starttime)\n",
    "    def on_train_batch_end(self, batch, logs = {}):\n",
    "        self.endtime = time.time()\n",
    "        self.end_batch_interference_list.append(self.endtime)\n",
    "        self.difference_batch_interference_list.append(self.endtime - self.starttime)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs = {}):\n",
    "        self.starttime = time.time()\n",
    "        self.start_list.append(self.starttime)\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        self.endtime = time.time()\n",
    "        self.end_list.append(self.endtime)\n",
    "        self.difference_list.append(self.endtime - self.starttime)\n",
    "            \n",
    "cb = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a26dd5-5b13-483b-a66e-f932674997fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0093 - categorical_accuracy: 0.9969 - val_loss: 0.0931 - val_categorical_accuracy: 0.9801\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0015 - categorical_accuracy: 0.9999 - val_loss: 0.0838 - val_categorical_accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 6.0174e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0863 - val_categorical_accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 5.7531e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0857 - val_categorical_accuracy: 0.9824\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 4.6926e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0850 - val_categorical_accuracy: 0.9820\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 3.4670e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0855 - val_categorical_accuracy: 0.9817\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 3.1057e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0867 - val_categorical_accuracy: 0.9820\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 2.9729e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0873 - val_categorical_accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0106 - categorical_accuracy: 0.9964 - val_loss: 0.1062 - val_categorical_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0039 - categorical_accuracy: 0.9989 - val_loss: 0.0906 - val_categorical_accuracy: 0.9815\n",
      "\n",
      " {'model_name': 'MLP', 'framework_name': 'TensorFlow', 'dataset': 'MNIST Digits', 'task': 'classification', 'Total Training Time': 7.20120906829834, 'Average Epoch Training Time': 0.061261439323425294, 'Average Batch Inference Time': 0.01269027317510739}\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Model...\n",
    "epoch_count = 10\n",
    "batch_count = 469\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs = epoch_count,\n",
    "    validation_data = ds_test,\n",
    "    callbacks = [cb]\n",
    ")\n",
    "\n",
    "def average_calculator(ls, num):\n",
    "    total = 0.0\n",
    "    average = 0.0\n",
    "    for val in range(len(ls)):\n",
    "        total += ls[val]\n",
    "    average = total / num\n",
    "    return average\n",
    "\n",
    "total_training_time = cb.end_train_time - cb.start_train_time\n",
    "average_epoch_training_time = average_calculator(cb.difference_list, epoch_count)\n",
    "average_batch_interference_time = average_calculator(cb.difference_batch_interference_list, batch_count)\n",
    "\n",
    "print(\"\\n\", metrics)\n",
    "\n",
    "metrics = {\n",
    "    \"model_name\": \"MLP\",\n",
    "    \"framework_name\": \"TensorFlow\",\n",
    "    \"dataset\": \"MNIST Digits\",\n",
    "    \"task\": \"classification\",\n",
    "    \"Total Training Time\" : total_training_time,\n",
    "    \"Average Epoch Training Time\" : average_epoch_training_time,\n",
    "    \"Average Batch Inference Time\" : average_batch_interference_time\n",
    "}\n",
    "\n",
    "with open(\"output.json\", \"w\") as outfile:\n",
    "    json.dump(metrics, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858bba4c-8c93-49b4-ba55-e3fc07d6613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 0s 818us/step - loss: 0.0227 - categorical_accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022661486640572548, 0.9945499897003174]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    ds_train\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
