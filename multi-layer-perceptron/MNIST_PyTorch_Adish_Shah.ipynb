{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYjVAR88R2QP",
        "outputId": "7ce43d3d-be8f-414b-d847-dd1e97d10d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.492628 \tEpoch Time: 6.26s\n",
            "Epoch: 2 \tTraining Loss: 0.210983 \tEpoch Time: 6.21s\n",
            "Epoch: 3 \tTraining Loss: 0.160320 \tEpoch Time: 6.19s\n",
            "Epoch: 4 \tTraining Loss: 0.137065 \tEpoch Time: 6.23s\n",
            "Epoch: 5 \tTraining Loss: 0.117955 \tEpoch Time: 6.34s\n",
            "Epoch: 6 \tTraining Loss: 0.105298 \tEpoch Time: 6.22s\n",
            "Epoch: 7 \tTraining Loss: 0.092336 \tEpoch Time: 6.20s\n",
            "Epoch: 8 \tTraining Loss: 0.086436 \tEpoch Time: 6.20s\n",
            "Epoch: 9 \tTraining Loss: 0.079494 \tEpoch Time: 6.24s\n",
            "Epoch: 10 \tTraining Loss: 0.075308 \tEpoch Time: 6.27s\n",
            "\n",
            "Average Epoch Training Time: 6.24s\n",
            "-------------------------------------------------------------------------\n",
            "Test Accuracy of     1: 98% (968/980)\n",
            "Test Accuracy of     2: 98% (1121/1135)\n",
            "Test Accuracy of     3: 98% (1013/1032)\n",
            "Test Accuracy of     4: 97% (988/1010)\n",
            "Test Accuracy of     5: 98% (967/982)\n",
            "Test Accuracy of     6: 96% (860/892)\n",
            "Test Accuracy of     7: 98% (939/958)\n",
            "Test Accuracy of     8: 96% (991/1028)\n",
            "Test Accuracy of     9: 97% (945/974)\n",
            "Test Accuracy of    10: 96% (977/1009)\n",
            "\n",
            "Average Test Loss(Model Evaluation): 0.079169\n",
            "\n",
            "Test Accuracy (Overall): 97% (9769/10000)\n",
            "\n",
            "Average Batch Inference Time: 895.66ms\n",
            "\n",
            "Total Training Time: 63.26s\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms.transforms import ToTensor\n",
        "import torch \n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_ds= torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_ds= torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=128, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds, batch_size=128, shuffle=False)\n",
        "\n",
        "examples = iter(test_dl)\n",
        "example_images, example_targets = examples.next()\n",
        "\n",
        "# for i in range(8):\n",
        "#   plt.subplot(2,4,i+1)\n",
        "#   plt.imshow(example_images[i][0], cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.fc1 = nn.Linear(28 * 28, 100)\n",
        "    self.fc2 = nn.Linear(100, 100)\n",
        "    self.fc3 = nn.Linear(100, 10)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001, betas=[0.9, 0.999])\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "model.train()\n",
        "tic_total_train = time.time()\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "   \n",
        "    train_loss = 0.0\n",
        "    tic_train_epoch = time.time()\n",
        "\n",
        "    \n",
        "    for data, target in train_dl:\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(data)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "       \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "       \n",
        "        train_loss += loss.item()*data.size(0)\n",
        "             \n",
        "    train_loss = train_loss/len(train_dl.dataset)\n",
        "    toc_train_epoch = time.time()\n",
        "    time_per_epoch = toc_train_epoch - tic_train_epoch\n",
        "    epoch_times.append(time_per_epoch)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tEpoch Time: {:.2f}s'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        time_per_epoch,\n",
        "        ))\n",
        "\n",
        "print(\"\\nAverage Epoch Training Time: {:.2f}s\".format(np.average(epoch_times)))\n",
        "\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "    \n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "tic_eval = time.time()\n",
        "for data, target in test_dl:\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # getting the current batch size\n",
        "    batch_size = data.size(0)\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1       \n",
        "toc_eval = time.time()\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i+1), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_dl.dataset)\n",
        "print('\\nAverage Test Loss(Model Evaluation): {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "print('Test Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n",
        "\n",
        "num_eval_batches = math.ceil(len(test_dl)/128)\n",
        "\n",
        "average_batch_inference_time = (1000* (toc_eval - tic_eval) / num_eval_batches) # in ms\n",
        "\n",
        "print(\"\\nAverage Batch Inference Time: {:.2f}ms\".format(average_batch_inference_time))\n",
        "\n",
        "toc_total_train = time.time()\n",
        "total_train_time = toc_total_train - tic_total_train\n",
        "\n",
        "print(\"\\nTotal Training Time: {:.2f}s\".format(total_train_time))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export JSON\n",
        "metrics = {\n",
        "    \"model_name\": \"MLP\",\n",
        "    \"framework_name\": \"PyTorch\",\n",
        "    \"dataset\": \"MNIST Digits\",\n",
        "    \"task\": \"classification\",\n",
        "    \"total_training_time\": total_train_time,         # in seconds\n",
        "    \"average_epoch_training_time\": np.average(epoch_times),  # in seconds\n",
        "    \"average_batch_inference_time\": average_batch_inference_time,  # in milliseconds\n",
        "    \"final_training_loss\": test_loss,\n",
        "    \"final_evaluation_accuracy\": 100. * np.sum(class_correct) / np.sum(class_total),\n",
        "}\n",
        "\n",
        "with open(\"m1-pytorch-mlp.json\", \"w\") as outfile:\n",
        "  json.dump(metrics, outfile)\n"
      ],
      "metadata": {
        "id": "hzKLVr20I94R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2y3I7-aRUiu",
        "outputId": "13d592dd-6343-4558-bc82-b8b8317a3f2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'MLP',\n",
              " 'framework_name': 'PyTorch',\n",
              " 'dataset': 'MNIST Digits',\n",
              " 'task': 'classification',\n",
              " 'total_training_time': 63.25790095329285,\n",
              " 'average_epoch_training_time': 6.235158848762512,\n",
              " 'average_batch_inference_time': 895.6584930419922,\n",
              " 'final_training_loss': 0.0791693767288234,\n",
              " 'final_evaluation_accuracy': 97.69}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}