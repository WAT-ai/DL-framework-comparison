{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Yota;\n",
    "using MLDatasets;\n",
    "using NNlib;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using Functors;\n",
    "using Optimisers;\n",
    "using Flux.Data;\n",
    "using Flux: onehotbatch, @epochs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Linear\n",
    "    W::AbstractMatrix{T} where T\n",
    "    b::AbstractVector{T} where T\n",
    "end\n",
    "\n",
    "@functor Linear\n",
    "\n",
    "# Init\n",
    "function Linear(in_features::Int, out_features::Int)\n",
    "    k_sqrt = sqrt(1 / in_features)\n",
    "    d = Uniform(-k_sqrt, k_sqrt)\n",
    "    return Linear(rand(d, out_features, in_features), rand(d, out_features))\n",
    "end\n",
    "Linear(in_out::Pair{Int, Int}) = Linear(in_out[1], in_out[2])\n",
    "\n",
    "function Base.show(io::IO, l::Linear)\n",
    "    o, i = size(l.W)\n",
    "    print(io, \"Linear($i=>$o)\")\n",
    "end\n",
    "\n",
    "# Forward\n",
    "(l::Linear)(x::Union{AbstractVector{T}, AbstractMatrix{T}}) where T = l.W * x .+ l.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logitcrossentropy (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logitcrossentropy(ŷ, y; dims = 1, agg = mean)\n",
    "    agg(.-sum(y .* logsoftmax(ŷ; dims = dims); dims = dims));\n",
    "  end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Net\n",
    "    fc1::Linear\n",
    "    fc2::Linear\n",
    "end\n",
    "\n",
    "@functor Net\n",
    "\n",
    "# Init\n",
    "Net() = Net(\n",
    "    Linear(28*28, 100),\n",
    "    Linear(100, 10)\n",
    ")\n",
    "\n",
    "# Forward\n",
    "function (model::Net)(x::AbstractArray)\n",
    "    x = reshape(x, 28*28, :)\n",
    "    x = model.fc1(x)\n",
    "    x = relu(x)\n",
    "    x = model.fc2(x)\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(dir=\"/Users/trevoryu/Code/data/mnist\", split=:train);\n",
    "test_dataset = MNIST(dir=\"/Users/trevoryu/Code/data/mnist\", split=:test);\n",
    "\n",
    "X_train = train_dataset.features;\n",
    "Y_train = train_dataset.targets;\n",
    "\n",
    "X_test = test_dataset.features;\n",
    "Y_test = test_dataset.targets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten features to be 784 dim\n",
    "X_train = reshape(X_train, 784, :);  # (dim x batch)\n",
    "X_test = reshape(X_test, 784, :);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert targets to one-hot vectors\n",
    "Y_train = onehotbatch(Y_train, 0:9);\n",
    "Y_test = onehotbatch(Y_test, 0:9);  # (dim x batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader((X_train, Y_train), shuffle=true, batchsize=128);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(Linear(784=>100), Linear(100=>10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make model\n",
    "mlp = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Adam optimizer\n",
    "# Default Β is (0.9, 0.999)\n",
    "state = Optimisers.setup(Optimisers.Adam(1e-3), mlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create objective function\n",
    "function loss_function(model::Net, x::AbstractArray, y::AbstractArray)\n",
    "    ŷ = model(x)\n",
    "    loss = logitcrossentropy(ŷ, y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.774987 seconds (162.82 k allocations: 1.951 GiB, 12.71% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 1 loss = 0.04094025307690705\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.646125 seconds (163.01 k allocations: 1.951 GiB, 10.26% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 2 loss = 0.03572923218462636\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.652080 seconds (163.01 k allocations: 1.951 GiB, 9.54% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 3 loss = 0.03166147383022924\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.682782 seconds (163.01 k allocations: 1.951 GiB, 11.74% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 4 loss = 0.027879119237525167\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.666789 seconds (163.01 k allocations: 1.951 GiB, 8.82% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 5 loss = 0.02481490266472439\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.624532 seconds (163.01 k allocations: 1.951 GiB, 8.85% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 6 loss = 0.021184432907923646\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.604429 seconds (163.01 k allocations: 1.951 GiB, 8.57% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 7 loss = 0.019366974012950174\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.622498 seconds (163.01 k allocations: 1.951 GiB, 8.82% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 8 loss = 0.016626981172646552\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.610364 seconds (163.01 k allocations: 1.951 GiB, 8.79% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 9 loss = 0.014004979298361142\n",
      "└ @ Main In[18]:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.661410 seconds (163.01 k allocations: 1.951 GiB, 10.90% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: epoch 10 loss = 0.012511318528209223\n",
      "└ @ Main In[18]:12\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:10\n",
    "    losses = []\n",
    "    @time begin\n",
    "        for (x, y) in loader\n",
    "            # loss_function does forward pass\n",
    "            # Yota.jl grad function computes parameter gradients\n",
    "            loss, g = grad(loss_function, mlp, x, y)\n",
    "            # Optimiser updates parameters\n",
    "            Optimisers.update!(state, mlp, g[2])\n",
    "            push!(losses, loss)\n",
    "            # TODO: Add accuracy computation\n",
    "        end\n",
    "        @info(\"epoch $epoch loss = $(mean(losses))\")\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
