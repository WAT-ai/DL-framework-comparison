{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f91157",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1583d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Yota;\n",
    "using MLDatasets;\n",
    "using NNlib;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using Functors;\n",
    "using Optimisers;\n",
    "using MLUtils: DataLoader;\n",
    "using OneHotArrays: onehotbatch\n",
    "using Knet:Knet,conv4, adam\n",
    "using Knet: dir, accuracy, progress, sgd, gc\n",
    "using Metrics;\n",
    "using TimerOutputs;\n",
    "using Flux: BatchNorm, kaiming_uniform, nfan;\n",
    "using Functors\n",
    "\n",
    "# Model creation\n",
    "using NNlib;\n",
    "using Flux: BatchNorm, Chain, GlobalMeanPool, kaiming_uniform, nfan;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using Functors;\n",
    "\n",
    "# Data processing\n",
    "using MLDatasets;\n",
    "using MLUtils: DataLoader;\n",
    "using MLDataPattern;\n",
    "using ImageCore;\n",
    "using Augmentor;\n",
    "using ImageFiltering;\n",
    "using MappedArrays;\n",
    "using Random;\n",
    "using Flux: DataLoader;\n",
    "# using OneHotArrays: onehotbatch\n",
    "\n",
    "\n",
    "# Training\n",
    "# using Yota;\n",
    "using Zygote;\n",
    "using Optimisers;\n",
    "using Metrics;\n",
    "using TimerOutputs;\n",
    "\n",
    "\n",
    "\n",
    "# Issue when running this\n",
    "#using Knet: Knet, dir, accuracy, progress, sgd, gc, Data, nll, relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aff91e",
   "metadata": {},
   "source": [
    "# Conv 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481a3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Conv2D{T}\n",
    "    w::AbstractArray{T, 4}\n",
    "    b::AbstractVector{T}\n",
    "    use_bias::Bool\n",
    "    padding::Int \n",
    "end\n",
    "\n",
    "@functor Conv2D (w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59da1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "function Conv2D(kernel_size::Tuple{Int, Int}, in_channels::Int, out_channels::Int;\n",
    "    bias::Bool=false, padding::Int=1)\n",
    "    w_size = (kernel_size..., in_channels, out_channels)\n",
    "    w = kaiming_uniform(w_size...)\n",
    "    (fan_in, fan_out) = nfan(w_size)\n",
    "    \n",
    "    if bias\n",
    "        # Init bias with fan_in from weights. Use gain = √2 for ReLU\n",
    "        bound = √3 * √2 / √fan_in\n",
    "        rng = Uniform(-bound, bound)\n",
    "        b = rand(rng, out_channels, Float32)\n",
    "    else\n",
    "        b = zeros(Float32, out_channels)\n",
    "    end\n",
    "\n",
    "    return Conv2D(w, b, bias, padding)\n",
    "end\n",
    "\n",
    "function (self::Conv2D)(x::AbstractArray; stride::Int=1, pad::Int=0, dilation::Int=1)\n",
    "    y = conv4(self.w, x; stride=stride, padding=self.padding, dilation=dilation)\n",
    "    if self.use_bias\n",
    "        # Bias is applied channel-wise\n",
    "        (w, h, c, b) = size(y)\n",
    "        bias = reshape(self.b, (1, 1, c, 1))\n",
    "        y = y .+ bias\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e934f",
   "metadata": {},
   "source": [
    "# ResNetLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e66be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNetLayer\n",
    "    conv1::Conv2D\n",
    "    conv2::Conv2D\n",
    "    bn1::BatchNorm\n",
    "    bn2::BatchNorm\n",
    "    f::Function\n",
    "    in_channels::Int\n",
    "    channels::Int\n",
    "    stride::Int\n",
    "end\n",
    "\n",
    "@functor ResNetLayer (conv1, conv2, bn1, bn2)\n",
    "\n",
    "function residual_identity(layer::ResNetLayer, x::AbstractArray{T, 4}) where {T<:Number}\n",
    "    (w, h, c, b) = size(x)\n",
    "    stride = layer.stride\n",
    "    if stride > 1\n",
    "        @assert ((w % stride == 0) & (h % stride == 0)) \"Spatial dimensions are not divisible by `stride`\"\n",
    "    \n",
    "        # Strided downsample\n",
    "        x_id = copy(x[begin:2:end, begin:2:end, :, :])\n",
    "    else\n",
    "        x_id = x\n",
    "    end\n",
    "\n",
    "    channels = layer.channels\n",
    "    in_channels = layer.in_channels\n",
    "    if in_channels < channels\n",
    "        # Zero padding on extra channels\n",
    "        (w, h, c, b) = size(x_id)\n",
    "        pad = zeros(w, h, channels - in_channels, b)\n",
    "        x_id = cat(x_id, pad; dims=3)\n",
    "    elseif in_channels > channels\n",
    "        error(\"in_channels > out_channels not supported\")\n",
    "    end\n",
    "    return x_id\n",
    "end\n",
    "\n",
    "function ResNetLayer(in_channels::Int, channels::Int; stride=1, f=relu)\n",
    "    bn1 = BatchNorm(in_channels)\n",
    "    conv1 = Conv2D((3, 3), in_channels, channels, bias=false)\n",
    "    bn2 = BatchNorm(channels)\n",
    "    conv2 = Conv2D((3, 3), channels, channels, bias=false)\n",
    "\n",
    "    return ResNetLayer(conv1, conv2, bn1, bn2, f, in_channels, channels, stride)\n",
    "end\n",
    "\n",
    "\n",
    "function (self::ResNetLayer)(x::AbstractArray)\n",
    "    identity = residual_identity(self, x)\n",
    "    z = self.bn1(x)\n",
    "    z = self.f(z)\n",
    "    z = self.conv1(z; pad=1, stride=self.stride)  # pad=1 will keep same size with (3x3) kernel\n",
    "    z = self.bn2(z)\n",
    "    z = self.f(z)\n",
    "    z = self.conv2(z; pad=1)\n",
    "\n",
    "    y = z + identity\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06e04e",
   "metadata": {},
   "source": [
    "# Testing ResNetLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdc72a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 10, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l = ResNetLayer(3, 10; stride=2);\n",
    "x = randn(Float32, (32, 32, 3, 4));\n",
    "y = l(x);\n",
    "size(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21b952",
   "metadata": {},
   "source": [
    "# Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8987f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: method definition for Linear at In[6]:22 declares type variable T but does not use it.\n"
     ]
    }
   ],
   "source": [
    "mutable struct Linear\n",
    "    W::AbstractMatrix{T} where T\n",
    "    b::AbstractVector{T} where T\n",
    "end\n",
    "\n",
    "@functor Linear\n",
    "\n",
    "# Init\n",
    "function Linear(in_features::Int, out_features::Int)\n",
    "    k_sqrt = sqrt(1 / in_features)\n",
    "    d = Uniform(-k_sqrt, k_sqrt)\n",
    "    return Linear(rand(d, out_features, in_features), rand(d, out_features))\n",
    "end\n",
    "Linear(in_out::Pair{Int, Int}) = Linear(in_out[1], in_out[2])\n",
    "\n",
    "function Base.show(io::IO, l::Linear)\n",
    "    o, i = size(l.W)\n",
    "    print(io, \"Linear(o)\")\n",
    "end\n",
    "\n",
    "# Forward\n",
    "(l::Linear)(x::AbstractArray) where T = l.W * x .+ l.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8c6ca",
   "metadata": {},
   "source": [
    "# Defining a Chain Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47a2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a chain of layers and a loss function:\n",
    "struct Chain1; layers; end\n",
    "(c::Chain1)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain1)(x,y) = nll(c(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02eca287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet20Model"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet Architecture\n",
    "\n",
    "mutable struct ResNet20Model\n",
    "    input_conv::Conv2D\n",
    "    resnet_blocks::Chain1\n",
    "    pool::GlobalMeanPool\n",
    "    linear::Linear\n",
    "end\n",
    "\n",
    "@functor ResNet20Model\n",
    "\n",
    "function ResNet20Model(in_channels::Int, num_classes::Int)\n",
    "    resnet_blocks = Chain1((\n",
    "        block_1 = ResNetLayer(16, 16),\n",
    "        block_2 = ResNetLayer(16, 16),\n",
    "        block_3 = ResNetLayer(16, 16),\n",
    "        block_4 = ResNetLayer(16, 32; stride=2),\n",
    "        block_5 = ResNetLayer(32, 32),\n",
    "        block_6 = ResNetLayer(32, 32),\n",
    "        block_7 = ResNetLayer(32, 64; stride=2),\n",
    "        block_8 = ResNetLayer(64, 64),\n",
    "        block_9 = ResNetLayer(64, 64)\n",
    "    ))\n",
    "    return ResNet20Model(\n",
    "        Conv2D((3, 3), in_channels, 16, bias=false),\n",
    "        resnet_blocks,\n",
    "        GlobalMeanPool(),\n",
    "        Linear(64, num_classes)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdef0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (self::ResNet20Model)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_blocks(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.linear(z)\n",
    "    return y\n",
    "end\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c15eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Slow fallback implementation invoked for conv!  You probably don't want this; check your datatypes.\n",
      "│   yT = Float64\n",
      "│   T1 = Float64\n",
      "│   T2 = Float32\n",
      "└ @ NNlib C:\\Users\\Yash\\.julia\\packages\\NNlib\\0QnJJ\\src\\conv.jl:285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Testing ResNet20 model\n",
    "# Expected output: (10, 4)\n",
    "m = ResNet20Model(3, 10);\n",
    "inputs = randn(Float32, (32, 32, 3, 4))\n",
    "outputs = m(inputs);\n",
    "size(outputs)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43380e",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84857fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32×32×3×45000 Array{Float32, 4}\n",
      "45000-element Vector{Int64}\n",
      "32×32×3×5000 Array{Float32, 4}\n",
      "5000-element Vector{Int64}\n",
      "32×32×3×10000 Array{Float32, 4}\n",
      "10000-element Vector{Int64}\n"
     ]
    }
   ],
   "source": [
    "# This loads the CIFAR-10 Dataset for training, validation, and evaluation\n",
    "xtrn,ytrn = CIFAR10.traindata(Float32, 1:45000)\n",
    "xval,yval =  CIFAR10.traindata(Float32, 45001:50000)\n",
    "xtst,ytst = CIFAR10.testdata(Float32)\n",
    "println.(summary.((xtrn,ytrn,xval, yval, xtst,ytst)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45acc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the data\n",
    "\n",
    "means = reshape([0.485, 0.465, 0.406], (1, 1, 3, 1))\n",
    "stdevs = reshape([0.229, 0.224, 0.225], (1, 1, 3, 1))\n",
    "normalize(x) = (x .- means) ./ stdevs\n",
    "\n",
    "train_x = normalize(xtrn);\n",
    "val_x = normalize(xval);\n",
    "test_x = normalize(xtst);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e93cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitobs (generic function with 11 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train-test split\n",
    "# Copied from https://github.com/JuliaML/MLUtils.jl/blob/v0.2.11/src/splitobs.jl#L65\n",
    "# obsview doesn't work with this data, so use getobs instead\n",
    "\n",
    "import MLDataPattern.splitobs;\n",
    "\n",
    "function splitobs(data; at, shuffle::Bool=false)\n",
    "    if shuffle\n",
    "        data = shuffleobs(data)\n",
    "    end\n",
    "    n = numobs(data)\n",
    "    return map(idx -> MLDataPattern.getobs(data, idx), splitobs(n, at))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c649cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Notebook testing: Use less data\n",
    "train_x, train_y = MLDatasets.getobs((train_x, ytrn), 1:500);\n",
    "\n",
    "val_x, val_y = MLDatasets.getobs((val_x, yval), 1:50);\n",
    "\n",
    "test_x, test_y = MLDatasets.getobs((test_x, ytst), 1:50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75266187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 3, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pad the training data for further augmentation\n",
    "train_x_padded = padarray(train_x, Fill(0, (4, 4, 0, 0)));  \n",
    "size(train_x_padded)  # Should be (40, 40, 3, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc788d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-step Augmentor.ImmutablePipeline:\n",
       " 1.) Permute dimension order to (3, 1, 2)\n",
       " 2.) Combine color channels into colorant RGB\n",
       " 3.) Either: (50%) Flip the X axis. (50%) No operation.\n",
       " 4.) Crop random window with size (32, 32)\n",
       " 5.) Split colorant into its color channels\n",
       " 6.) Permute dimension order to (2, 3, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = PermuteDims((3, 1, 2)) |> CombineChannels(RGB) |> Either(FlipX(), NoOp()) |> RCropSize(32, 32) |> SplitChannels() |> PermuteDims((2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815faf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an output array for augmented images\n",
    "outbatch(X) = Array{Float32}(undef, (32, 32, 3, nobs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e86e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmentbatch (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that takes a batch (images and targets) and augments the images\n",
    "augmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d362ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The specified values for size and/or count will result in 4 unused data points\n",
      "└ @ MLDataPattern C:\\Users\\Yash\\.julia\\packages\\MLDataPattern\\KlSmO\\src\\dataview.jl:205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shuffled and batched dataset of augmented images\n",
    "train_batch_size = 16\n",
    "\n",
    "train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2386c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Validation data\n",
    "test_batch_size = 32\n",
    "\n",
    "val_loader = DataLoader((val_x, val_y), shuffle=true, batchsize=test_batch_size);\n",
    "test_loader = DataLoader((test_x, test_y), shuffle=true, batchsize=test_batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05599606",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd7aadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sparse Cross Entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6c4d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse_logit_cross_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    sparse_logit_cross_entropy(logits, labels)\n",
    "\n",
    "Efficient computation of cross entropy loss with model logits and integer indices as labels.\n",
    "Integer indices are from [0,  N-1], where N is the number of classes\n",
    "Similar to TensorFlow SparseCategoricalCrossEntropy\n",
    "\n",
    "# Arguments\n",
    "- `logits::AbstractArray`: 2D model logits tensor of shape (classes, batch size)\n",
    "- `labels::AbstractArray`: 1D integer label indices of shape (batch size,)\n",
    "\n",
    "# Returns\n",
    "- `loss::Float32`: Cross entropy loss\n",
    "\"\"\"\n",
    "# function sparse_logit_cross_entropy(logits, labels)\n",
    "#     log_probs = logsoftmax(logits);\n",
    "#     # Select indices of labels for loss\n",
    "#     log_probs = map((x, i) -> x[i + 1], eachslice(log_probs; dims=2), labels);\n",
    "#     loss = -mean(log_probs);\n",
    "#     return loss\n",
    "# end\n",
    "\n",
    "function sparse_logit_cross_entropy(logits, labels)\n",
    "    log_probs = logsoftmax(logits);\n",
    "    inds = CartesianIndex.(labels .+ 1, axes(log_probs, 2));\n",
    "    # Select indices of labels for loss\n",
    "    log_probs = log_probs[inds];\n",
    "    loss = -mean(log_probs);\n",
    "    return loss\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3998a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create model with 3 input channels and 10 classes\n",
    "model = ResNet20Model(3, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fa4497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup AdamW optimizer\n",
    "β = (0.9, 0.999);\n",
    "decay = 1e-4;\n",
    "state = Optimisers.setup(Optimisers.Adam(1e-3, β, decay), model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b852506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x, y) = first(train_batches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e71cc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, g = grad(loss_function, model, x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a9a8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ResNet5\n",
    "    input_conv::Conv2D\n",
    "    resnet_block::ResNetLayer\n",
    "    pool::GlobalMeanPool\n",
    "    linear::Linear\n",
    "end\n",
    "\n",
    "@functor ResNet5\n",
    "\n",
    "function ResNet5(in_channels::Int, num_classes::Int)\n",
    "    return ResNet5(\n",
    "        Conv2D((3, 3), in_channels, 16, bias=false),\n",
    "        ResNetLayer(16, 16),\n",
    "        GlobalMeanPool(),\n",
    "        Linear(16, num_classes)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (self::ResNet5)(x::AbstractArray)\n",
    "    z = self.input_conv(x)\n",
    "    z = self.resnet_block(z)\n",
    "    z = self.pool(z)\n",
    "    z = dropdims(z, dims=(1, 2))\n",
    "    y = self.linear(z)\n",
    "    return y\n",
    "end\n",
    "\n",
    "\n",
    "# function loss_function(model::ResNet5, x::AbstractArray, y::AbstractArray)\n",
    "#     ŷ = model(x)\n",
    "#     loss = sparse_logit_cross_entropy(ŷ, y)\n",
    "#     return loss\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "028a6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Yota is unable to compute gradients through the ResNet for some reason, maybe due to residual connections?\n",
    "# loss, g = grad(loss_function, model, x, y)\n",
    "model = ResNet5(3, 10);\n",
    "\n",
    "# loss, g = Zygote.gradient(loss_function, model, x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "696231c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d23487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet5(Conv2D{Float32}([-0.3269322 -0.09079589 -0.30220258; 0.29980195 -0.35697645 -0.43193826; 0.41894063 -0.27608046 -0.35023037;;; -0.11048572 -0.18733561 -0.048941202; -0.25535512 0.41386655 0.23646444; 0.1226552 0.19139434 -0.3201441;;; -0.2881651 0.4041223 -0.11729951; 0.28896266 0.124178275 0.10890088; -0.07136462 0.37597623 0.2907424;;;; 0.0116342725 -0.06491064 0.03947901; 0.36589766 -0.31363672 0.32354057; -0.101177834 0.22076249 0.26570976;;; -0.22781743 -0.16796216 0.079579934; 0.43243396 -0.18935399 0.3949348; -0.3725451 -0.06775151 0.21907443;;; -0.05270441 -0.43405735 -0.44125763; -0.47045088 -0.30292767 0.014733751; -0.04850591 -0.2133474 0.2412362;;;; 0.2572607 0.18735757 -0.33566207; -0.03157889 -0.04323261 0.1315869; -0.16356815 -0.23604983 0.051579874;;; -0.3262316 0.40397793 0.07843399; 0.17368728 0.31032175 -0.2273731; -0.20191403 0.11151084 0.33216488;;; -0.34083363 -0.46381113 0.055753145; -0.44104743 0.31393462 0.2622986; 0.13619547 -0.12979876 -0.043511562;;;; … ;;;; -0.020386824 -0.104114234 0.37638608; 0.41557428 -0.19767518 0.15894295; 0.150955 0.4521936 -0.26687187;;; 0.38604698 0.30180404 -0.1059084; -0.15032865 -0.031554278 -0.21704273; -0.03794346 0.3485954 0.38278958;;; -0.3071966 -0.3373205 0.26615357; 0.4422373 0.13577293 -0.10324652; 0.2894867 -0.23344572 0.39201385;;;; -0.13550712 0.30746755 0.38600484; 0.35319903 0.27227426 -0.42721114; -0.4167391 0.460941 0.23783916;;; 0.45264333 0.30202055 -0.32739767; -0.34008625 -0.23484135 0.19659689; -0.14264174 -0.09916833 0.27199847;;; -0.38800704 -0.060515907 0.4428402; 0.24729028 0.38564798 0.008954014; 0.10717848 0.3565583 -0.40317935;;;; 0.29413882 0.032473866 -0.24675108; 0.18658455 0.4415373 -0.07814981; 0.33296683 -0.1115019 -0.33509403;;; -0.24343053 0.042397596 0.35703608; 0.36186588 -0.05911843 -0.08993424; 0.13785711 -0.26265797 -0.067820854;;; -0.10355408 -0.26968983 0.097447224; -0.25024468 -0.1599089 0.4510931; 0.4365045 0.18134817 0.32099614], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], false, 1), ResNetLayer(Conv2D{Float32}([0.19761112 0.13021815 -0.028087448; -0.00057760417 -0.11352962 0.05831184; 0.124577686 0.089965284 0.13280511;;; -0.11783607 0.089995995 -0.1501678; -0.015031724 -0.012284083 -0.0898654; -0.09346841 -0.1621385 -0.0109067345;;; 0.17110728 -0.10372673 -0.015643882; 0.008885473 0.09228887 0.20323306; 0.015771464 -0.12023175 0.039679002;;; … ;;; -0.046293672 0.0779443 0.011689981; 0.122653276 -0.106488414 0.16222343; 0.006254584 -0.017572897 0.07593362;;; 0.0962515 0.18770924 0.19851086; -0.13754818 -0.029091569 0.06325006; 0.19043466 -0.08298591 0.17023039;;; -0.061017822 0.17036065 0.06359598; -0.005008466 -0.15680619 0.1233305; 0.17700247 0.20328574 -0.16379757;;;; -0.18611959 -0.043676604 0.108012736; 0.02672942 -0.13492495 0.15822719; -0.002692112 0.16126484 -0.025754329;;; -0.15724711 -0.04828544 -0.1707655; -0.0970394 -0.055499617 -0.024079112; 0.025048656 -0.082812436 -0.022185529;;; -0.1882148 0.16506943 0.000598823; -0.0912264 -0.16550767 -0.16717595; 0.06827358 0.17189996 -0.16707191;;; … ;;; 0.18228532 -0.17576592 -0.18167828; 0.19565201 -0.20267504 -0.18348633; -0.15575626 0.15550001 -0.14896752;;; -0.08209669 0.15093498 -0.11133591; -0.05105649 0.022263639 0.027264051; -0.02951181 0.18026373 -0.07041432;;; 0.025740579 0.075161055 -0.0525457; 0.092696406 -0.09947786 -0.12829517; -0.069097444 0.12314727 -0.1672388;;;; 0.10623432 -0.057691578 0.119959146; 0.03539229 -0.022670422 -0.111270726; 0.008098309 0.0037883115 -0.026243139;;; -0.070837826 -0.11017056 -0.178822; 0.06665229 -0.005612837 0.07103156; 0.1561577 0.031744555 0.0140344165;;; 0.15617746 -0.14973398 0.07564629; 0.0016903019 0.18394831 0.09675205; 0.19826071 -0.09340203 0.1700775;;; … ;;; 0.069550656 0.14834794 -0.06968259; 0.20270519 0.11043808 0.027695874; 0.13334787 0.16532846 0.048797905;;; 0.18591698 0.018436953 -0.0032594716; -0.08772257 -0.052733872 -0.14566335; 0.011975072 -0.15187715 0.10042701;;; 0.112629846 0.18635167 0.16804218; -0.19342335 0.010884567 0.14426668; -0.059680305 -0.038495857 0.19673485;;;; … ;;;; 0.12924753 0.11957796 -0.107034236; -0.15904024 -0.1602915 -0.094139844; 0.08867885 0.17599945 -0.04848101;;; -0.10934039 -0.19765444 -0.14756997; 0.17149675 0.14435652 -0.10002485; 0.18451841 0.066142604 0.17169759;;; -0.11077233 -0.0039441674 -0.069028825; -0.110270225 0.00804806 -0.080900356; -0.16658163 0.054695323 -0.015006443;;; … ;;; 0.00212283 0.18980761 -0.122687295; -0.115651555 -0.14763168 -0.06032928; -0.18875845 0.16435969 0.015897948;;; -0.16687778 -0.13686112 -0.10878749; -0.06288342 0.18291253 0.06357345; 0.09998129 0.1873411 0.08618598;;; -0.08974118 -0.0026351716 0.16592684; 0.12683599 -0.0756004 -0.058696333; -0.025129566 -0.17873748 0.15622494;;;; -0.020486929 -0.1648232 0.0033708948; 0.07356035 -0.04425343 -0.006855549; -0.18207838 0.07768629 -0.11125955;;; 0.05911343 -0.13387455 -0.02985895; 0.19365218 -0.0906411 -0.047491293; 0.1927835 -0.12751262 -0.13904938;;; 0.09187676 0.122309804 0.055273946; 0.1549648 0.06880033 -0.11684039; -0.10373542 0.018027786 -0.1502131;;; … ;;; -0.013978474 -0.051094815 -0.0014352868; -0.046254106 0.19333138 0.0050440175; 0.02186895 -0.083350666 -0.20366172;;; 0.087388806 -0.12761207 -0.027745271; -0.13694362 -0.14262795 0.15379757; -0.088099465 0.05600551 0.05024689;;; -0.18494785 3.431023f-5 -0.059908554; -0.0059224563 0.1425408 -0.02109383; 0.08903239 0.13319586 -0.1353602;;;; 0.0057842666 0.15523006 -0.031229122; -0.19541235 0.051155504 0.06527311; -0.1730501 -0.15493153 -0.1712542;;; 0.15538698 0.19521399 -0.061315224; 0.05348293 -0.15681091 0.06969483; -0.15938468 0.00255144 -0.008160578;;; -0.042394936 -0.023364875 0.030308511; -0.106786154 -0.062052142 0.110279866; -0.024075657 -0.20078343 -0.11427486;;; … ;;; 0.18105797 -0.13237794 -0.1409754; 0.19100334 -0.061168298 0.046601903; 0.14125203 0.17658699 -0.14446235;;; 0.05207166 0.06348066 -0.09771767; 0.0501899 0.09775206 0.1500323; -0.048741743 -0.13970241 -0.013351497;;; 0.11777932 -0.08002654 0.18714364; 0.12242211 0.17391886 0.12460178; -0.0737201 -0.15127876 -0.10289584], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], false, 1), Conv2D{Float32}([0.09717922 -0.03407784 0.014590169; -0.18445018 0.12831593 -0.07739436; -0.09349194 0.0037209808 -0.13268006;;; 0.17895766 -0.02247517 -0.037817243; -0.111089125 0.12584838 0.0016550183; 0.077631414 -0.044876367 -0.14228758;;; 0.13512933 0.14910595 -0.07057957; -0.121997386 0.13264237 0.19979271; -0.20085463 0.11576198 0.14067839;;; … ;;; 0.10820168 0.12200413 -0.08980403; 0.0011746995 0.1944284 0.18440181; 0.1767769 0.026093902 0.12368353;;; -0.007022744 -0.11667823 -0.20263171; 0.17421563 -0.11981526 -0.049599864; -0.15285212 -0.11957154 0.11077546;;; -0.158289 0.14341965 0.027710011; 0.1390186 -0.12730537 -0.16582859; -0.12259298 -0.11377486 -0.056429546;;;; 0.13843888 0.03513197 -0.15407993; -0.022550944 0.13677955 0.10618293; -0.14883694 0.16104752 -0.033526104;;; 0.11633827 0.073986895 0.039874643; 0.017279312 0.07693811 0.093623415; 0.10816275 -0.20379694 0.018923648;;; 0.15248454 0.06787851 -0.01800759; 0.09909373 -0.060843762 -0.027705412; -0.099589966 -0.1385283 -0.14809528;;; … ;;; -0.16959943 -0.06297494 0.05770058; 0.20113298 -0.047386974 0.11995617; -0.0032085418 -0.022590097 0.010460361;;; -0.18173099 0.13940151 -0.045853406; 0.07445716 0.10802089 -0.18385637; 0.12254616 -0.1648605 -0.1824452;;; -0.011050132 0.12620825 -0.021450827; 0.1770418 0.116070434 -0.091566995; -0.19971325 -0.16312777 -0.013281781;;;; -0.035456408 -0.036289588 -0.05979168; 0.09422635 -0.056371607 -0.0059971116; -0.19720648 0.015351248 -0.09199891;;; -0.03359222 0.0419892 0.18662222; -0.05208587 0.090805836 -0.073787235; -0.0937151 0.044613346 0.16400264;;; -0.10861183 0.17393792 -0.100663245; -0.09707624 -0.09358217 -0.17184801; 0.081750296 -0.076938204 0.06963327;;; … ;;; 0.108367175 -0.14059828 0.012450817; -0.045001905 -0.19173874 0.15082036; -0.008574759 0.15566646 0.14164986;;; -0.1068494 -0.030200982 0.17375617; 0.08390958 0.08448434 0.17300947; -0.16909282 0.056779485 0.03290582;;; -0.07413019 -0.031639017 0.0054012574; 0.033854 0.0916983 -0.18244815; 0.10101544 0.15076157 -0.16013426;;;; … ;;;; -0.063150845 0.17775898 0.1134759; -0.058250155 -0.0747142 0.15499249; -0.05641818 0.073472485 -0.17872544;;; 0.2006494 0.047009416 -0.006391436; -0.07353716 -0.09418866 -0.17701323; 0.024081083 -0.19869477 -0.00069250696;;; -0.049676735 0.0745745 -0.13708827; 0.08180036 -0.02534971 0.03376078; 0.071060985 0.17471206 -0.16068852;;; … ;;; 0.049811736 -0.11532743 0.002412666; 0.16178377 0.1469855 0.10922075; 0.04306834 0.057045255 -0.16866772;;; -0.013301638 -0.15541886 -0.035264272; 0.072164506 0.16410089 -0.09112215; 0.15948404 0.11376505 -0.10438497;;; 0.09450845 -0.19718246 0.073083684; 0.051564816 -0.033912666 -0.1722798; -0.047565997 -0.014022055 0.12652722;;;; 7.1759474f-5 -0.031632643 -0.09353316; 0.027056292 0.035871707 -0.011876182; 0.17951545 -0.13125665 -0.070746765;;; 0.059760485 -0.118754365 0.093996614; 0.13821077 0.19534363 0.12683688; 0.15409826 -0.17226508 -0.051132996;;; -0.092778996 -0.079336025 -0.10923138; 0.08583115 -0.0496824 0.012007193; 0.16740225 0.19941543 -0.06619081;;; … ;;; -0.059872467 0.015607577 0.13966718; 0.10251013 0.030340316 0.20154124; 0.10072651 0.06240758 -0.19964255;;; 0.19304037 0.102634646 0.15421943; 0.15746589 0.096430525 -0.04338655; 0.044689316 -0.047149528 -0.011374255;;; -0.026993804 -0.069641635 -0.063028984; 0.052857243 -0.08376117 -0.021661483; 0.09019801 -0.0031467103 -0.18673009;;;; 0.14249101 -0.18121263 0.020420937; -0.19246987 -0.011450296 -0.1786581; -0.0054819956 -0.016487014 -0.2034004;;; 0.17387968 -0.16070417 0.13330147; 0.07486626 0.16504952 -0.073846295; -0.14962983 -0.09689917 0.000648001;;; -0.15290444 0.17162122 0.0069305687; -0.06845603 -0.1037042 -0.13593975; 0.15990376 -0.08033438 -0.14466582;;; … ;;; -0.029019274 -0.16538228 0.11829052; 0.18074305 -0.04143785 0.16447136; 0.041418746 -0.17317066 0.11413952;;; 0.14402567 -0.030171514 0.10105601; -0.13740699 -0.02441596 0.11153571; 0.086634375 -0.15125358 0.14048335;;; 0.05758249 0.118906185 -0.10497864; -0.17066532 -0.044436127 0.023161229; -0.14597139 -0.03848912 0.17103036], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], false, 1), BatchNorm(16), BatchNorm(16), NNlib.relu, 16, 16, 1), GlobalMeanPool(), Linear(o))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01294ff6",
   "metadata": {},
   "source": [
    "# Training Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74f3f1da",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: progress! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: progress! not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ .\\In[31]:12 [inlined]",
      " [2] macro expansion",
      "   @ C:\\Users\\Yash\\.julia\\packages\\TimerOutputs\\4yHI4\\src\\TimerOutput.jl:237 [inlined]",
      " [3] macro expansion",
      "   @ .\\In[31]:11 [inlined]",
      " [4] top-level scope",
      "   @ C:\\Users\\Yash\\.julia\\packages\\TimerOutputs\\4yHI4\\src\\TimerOutput.jl:237 [inlined]",
      " [5] top-level scope",
      "   @ .\\In[31]:0",
      " [6] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss(test_x, test_y) = nll(model(test_x), test_y)\n",
    "evalcb = () -> (loss(test_x, test_y)) #function that will be called to get the loss \n",
    "const to = TimerOutput() # creating a TimerOutput, keeps track of everything\n",
    "\n",
    "\n",
    "@timeit to \"Train Total\" begin\n",
    "    for epoch in 1:10\n",
    "        train_epoch = epoch > 1 ? \"train_epoch\" : \"train_ji\"\n",
    "        @timeit to train_epoch begin\n",
    "            progress!(adam(model, train_batches; lr = 1e-3))\n",
    "        end\n",
    "        \n",
    "        evaluation = epoch > 1 ? \"evaluation\" : \"eval_jit\"\n",
    "        @timeit to evaluation begin\n",
    "            accuracy(model, train_batches)\n",
    "        end \n",
    "        \n",
    "    end \n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b3c8d",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02f69609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function evaluate(model, test_loader)\n",
    "#     preds = []\n",
    "#     targets = []\n",
    "#     for (x, y) in test_loader\n",
    "#         # Get model predictions\n",
    "#         # Note argmax of nd-array gives CartesianIndex\n",
    "#         # Need to grab the first element of each CartesianIndex to get the true index\n",
    "#         logits = model(x)\n",
    "#         ŷ = map(i -> i[1], argmax(logits, dims=1))\n",
    "#         append!(preds, ŷ)\n",
    "\n",
    "#         # Get true labels\n",
    "#         append!(targets, y)\n",
    "#     end\n",
    "#     accuracy = sum(preds .== targets) / length(targets)\n",
    "#     return accuracy\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2072bd8",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc39bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Setup timing output\n",
    "# const to = TimerOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b5c088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # last_loss = 0;\n",
    "# # @timeit to \"total_training_time\" begin\n",
    "#     for epoch in 1:10\n",
    "#         timing_name = epoch > 1 ? \"average_epoch_training_time\" : \"train_jit\"\n",
    "\n",
    "#         # Create lazily evaluated augmented training data\n",
    "#         train_batches = mappedarray(augmentbatch, batchview(shuffleobs((train_x_padded, train_y)), size=train_batch_size));\n",
    "\n",
    "#         @timeit to timing_name begin\n",
    "#             losses = []\n",
    "#             for (x, y) in train_batches\n",
    "#                 # loss_function does forward pass\n",
    "#                 # Yota.jl grad function computes model parameter gradients in g[2]\n",
    "#                 loss, g = grad(loss_function, model, x, y)\n",
    "                \n",
    "#                 # Optimiser updates parameters\n",
    "#                 Optimisers.update!(state, model, g[2])\n",
    "#                 push!(losses, loss)\n",
    "#             end\n",
    "#             last_loss = mean(losses)\n",
    "#             @info(\"epoch (mean(losses))\")\n",
    "#         end\n",
    "#         # timing_name = epoch > 1 ? \"average_inference_time\" : \"eval_jit\"\n",
    "#         # @timeit to timing_name begin\n",
    "#         #     acc = evaluate(model, test_loader)\n",
    "#         #     @info(\"epoch (acc)\")\n",
    "#         # end\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955c486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
